\documentclass[a4paper,10pt]{report}
\usepackage{cours}
\usepackage{pifont}

\begin{document}
\everymath{\displaystyle}

\begin{center}
\textit{{ {\huge TD 5 : Matrices et applications linéaires }}}
\end{center}

\bigskip

\noindent Dans la suite, $\mathbb{K}$ désignera $\mathbb{R}$ ou $\mathbb{C}$.

\medskip

\begin{center}
\textit{{ {\large Calcul matriciel}}}
\end{center}

\begin{Exa} Soient $(a,b) \in \mathbb{R}^2$ et $A$ définie par :
$$ A = \begin{pmatrix}
a & b \\
0  & a
\end{pmatrix}$$ 
Déterminer toutes les puissances de $A$.
\end{Exa}

\corr On a :
$$ A = a I_2 + b T \; \hbox{ où } \; T = \begin{pmatrix}
0 & 1 \\
0 & 0
\end{pmatrix}$$
Les matrices $I_2$ et $T$ commutent donc les matrices $a I_2$ et $bT$ commutent. D'après la formule du binôme de Newton, on a pour tout entier $n \geq 0$ :
$$ A^n = \sum_{k=0}^n \binom{n}{k} b^k T^k a^{n-k} I_2^{n-k} = \sum_{k=0}^n \binom{n}{k} b^k T^k a^{n-k} $$
Par simple calcul, on a $T^2 = 0_2$. Ainsi, pour tout entier $n \geq 0$,
\begin{align*}
 A^n  &= \binom{n}{0} b^0 T^0 a^{n-0} + \binom{n}{1} b^1 T^1 a^{n-1} \\
 & = a^n I_2 + nba^{n-1} T \\
 & = \begin{pmatrix}
 a^n & nba^{n-1} \\
 0 & a^n \\
 \end{pmatrix}
 \end{align*}
 
 \medskip

\begin{Exa} Soient $n \in \mathbb{N}^*$ et $M$ une matrice de $\mathcal{M}_n(\mathbb{K})$. On suppose que $M-I_n$ est nilpotente. Montrer que $M$ est inversible.
\end{Exa}

\corr D'après l'énoncé, il existe un entier naturel $k \geq 1$ tel que $(M-I_n)^k = 0_n$. Les matrices $M$ et $I_n$ commutent donc d'après la formule du binôme de Newton, on a :
$$ \sum_{j=0}^k \binom{k}{j} M^j (-I_n)^{k-j} = 0_n$$
et ainsi :
$$ (-1)^k I_n + \sum_{j=1}^k \binom{k}{j} M^j (-1)^{k-j} = 0_n$$
On a alors :
$$ M \left(\sum_{j=1}^k \binom{k}{j} M^{j-1} (-1)^{k-j} \right) = (-1)^{k+1} I_n$$
et finalement :
$$ M \left(\sum_{j=1}^k \binom{k}{j} M^{j-1} (-1)^{1+j} \right)= I_n$$
Ainsi, $M$ est inversible et :
$$ M^{-1} = \sum_{j=1}^k \binom{k}{j} M^{j-1} (-1)^{1+j} $$

\medskip

 \begin{Exa} Soient $n \geq 1$ et $A = (a_{ij})_{1 \leq i,j \leq n}$ une matrice de $\mathcal{M}_n(\mathbb{R})$. On suppose que pour tout $i \in \Interv{1}{n}$,
$$ \vert a_{ii} \vert > \sum_{k \neq i} \vert a_{ik} \vert $$
Montrer que $A$ est inversible.
\end{Exa}

\corr Supposons par l'absurde que $A$ n'est pas inversible. Il existe alors un vecteur $X = \begin{pmatrix}
x_1 \\
\vdots \\
x_n
\end{pmatrix}$, non nul, appartenant au noyau de $A$ donc $AX= 0$ ($0$ étant un abus de notation pour le vecteur colonne nul). Il existe un entier $j \in \Interv{1}{n}$ tel que :
$$ \vert x_j \vert = \max_{1 \leq i \leq n} \vert x_i \vert$$
Notons que le maximum existe car l'ensemble associé est un ensemble fini de $\mathbb{R}$. $X$ étant non nul, un des réels $x_i$ ($1 \leq i \leq n$) est non nul donc $\vert x_j \vert >0$. Sachant que $AX=0$, on a d'après la formule du produit matriciel que pour tout $i \in \Interv{1}{n}$,
$$ \sum_{k=1}^n a_{i,k} x_k = 0$$
En particulier :
$$ \sum_{k=1}^n a_{j,k} x_k = 0$$
On a donc :
$$ a_{j,j} x_j = - \sum_{k \neq j} a_{j,k} x_k$$
D'après l'inégalité triangulaire, on a alors :
$$ \vert a_{j,j} \vert \times \vert x_j \vert = \left\vert  \sum_{k \neq j} a_{j,k} x_k \right\vert \leq \sum_{k \neq j} \vert a_{j,k} \vert \times \vert x_k \vert$$
Par définition de $j$, et par positivité de tous les termes, on en déduit que :
$$  \vert a_{j,j} \vert \times \vert x_j \vert \leq \sum_{k \neq j} \vert a_{j,k} \vert \times \vert x_j \vert =  \vert x_j \vert\sum_{k \neq j} \vert a_{j,k} \vert$$
Or $\vert x_j \vert$ est non nul donc :
$$ \vert a_{j,j} \vert  \leq  \sum_{k \neq j} \vert a_{j,k} \vert$$
ce qui est absurde au vu de l'hypothèse de l'énoncé.

\medskip

\begin{Exa} Soient $n\geq 1$ et $A$, $B$ deux matrices de $\mathcal{M}_n(\mathbb{K})$. Montrer que si $I_n - AB$ est inversible alors $I_n - BA$ est inversible.
\end{Exa} 

\corr Supposons que $I_n -AB$ est inversible. Montrons que $I_n-BA$ est inversible. Il suffit de montrer que le noyau de cette matrice est réduit au vecteur nul que l'on notera abusivement $0$. Si $X$ est dans le noyau de $I_n-BA$ alors $(I_n- BA)X=0$ donc $BAX=X$. En multipliant par $A$, on en déduit que $ABAX=AX$ donc 
$$ (AB-I_n)(AX)=0$$
Or $I_n -AB$ est inversible donc $BA-I_n$ aussi. Ainsi, $AX=0$. Sachant que $BAX=X$ on en déduit que $X=0$. Le noyau de $I_n-BA$ est réduit au vecteur nul donc cette matrice est inversible.

\medskip

\noindent Ce n'est pas demandé mais on peut déterminer l'inverse de $I_n-BA$. La matrice $I_n-AB$ étant supposée inversible, Il existe une matrice $P$ inversible tel que :
$$ I_n= (I_n-AB)P = P- ABP$$
On a alors en multipliant par $A$ à droite : 
$$ A = PA-ABPA$$
puis en multipliant par $B$ à gauche :
$$ BA = BPA- B(ABP)A$$
On a ainsi :
$$ 0_n = -BA + BPA- B(ABP)A$$
puis :
$$ I_n = I_n - BA +BPA - BA(BPA) = I_n - BA + (I_n- BA) BPA$$
et ainsi :
$$ I_n = (I_n-BA)(I_n+BPA)$$
On retrouve que $I_n-BA$ est inversible et :
$$ (I_n-BA)^{-1} = I_n+BPA = I_n+B(I_n-AB)^{-1}A$$

\medskip
\begin{Exa} Soient $n \geq 2$ et $D= \textrm{diag}(\lambda_1, \ldots, \lambda_n)$ ou $\lambda_1$, $\ldots$, $\lambda_n$ sont $n$ éléments de $\mathbb{K}$ deux à deux distincts.
\begin{enumerate}
\item Soit $M \in \mathcal{M}_n(\mathbb{K})$. Montrer que $M$ commute avec $D$ si et seulement si $M$ est diagonale.
\item Soit $M \in \mathcal{M}_n(\mathbb{K})$ une matrice diagonale. Montrer qu'il existe un polynôme $P$ de degré au plus $n-1$ tel que $M=P(D)$.
\end{enumerate}
\end{Exa}

\corr \begin{enumerate}
\item Soit $M \in \mathcal{M}_n(\mathbb{K})$. 
\begin{itemize}
\item Si $M$ est diagonale, il est évident que $M$ commute avec $D$ qui est aussi diagonale.
\item Supposons que $M=(m_{i,j})$ commute avec $D=(d_{i,j})$. Posons $A=MD=(a_{i,j})$ et $B=DM=(b_{i,j})$. On a donc $A=B$. Soit $(i,j) \in \Interv{1}{n}^2$ tel que $i \neq j$. On a :
$$ a_{i,j} = \sum_{k=1}^n m_{i,k} d_{k,j} = m_{i,j} d_{j,j} = \lambda_j m_{i,j}$$
car $d_{j,k}$ est nul si $j \neq k$ car $D$ est diagonale.
De même, on a :
$$ b_{i,j} = \sum_{k=1}^n d_{i,k} m_{k,j} = d_{i,i}m_{i,j} = \lambda_i m_{i,j}$$
Sachant que $A=B$, on en déduit que :
$$ \lambda_j m_{i,j} = \lambda_i m_{i,j}$$
Sachant que $i \neq j$, on a par hypothèse que $\lambda_j \neq \lambda_i$ donc $m_{i,j}=0$. Ainsi, tous les coefficients hors de la diagonale de $M$ sont nuls et donc $M$ est diagonale.
\end{itemize}
Finalement, $M$ commute avec $D$ si et seulement si $M$ est diagonale.
\item Soit $M \in \mathcal{M}_n(\mathbb{K})$ une matrice diagonale. De manière évidente, si $P$ est un polynôme alors :
$$ P(D) = \textrm{diag}(P(\lambda_1), \ldots, P(\lambda_n))$$
Notons $M= \textrm{diag}(a_1, \ldots, a_n)$. Répondre à la question posée revient à déterminer un polynôme de degré au plus $n-1$ tel que pour tout $i \in \Interv{1}{n}$, $P(\lambda_i)= a_i$. Sachant que les scalaires $\lambda_i$ sont deux à deux distincts, il suffit de connaitre les polynômes de Lagrange ! Posons :
$$ P(X) = \sum_{i=1}^n a_i L_i(X)$$
où pour tout $i \in \Interv{1}{n}$,
$$ L_i(X) = \prod_{k \in \Interv{1}{n} \setminus \lbrace i \rbrace} \dfrac{X-\lambda_k}{\lambda_i- \lambda_k}$$
Le polynôme $P$ est une somme de polynômes de degré $n-1$ donc est bien de degré au plus $n-1$ et vérifie pour tout $i \in \Interv{1}{n}$ que $P(\lambda_i)= a_i$ car (de manière usuelle) $L_i(\lambda_t) = \delta_{i,t}$.

\end{enumerate}


 \newpage

\begin{center}
\textit{{ {\large Matrice d'application linéaire}}}
\end{center}

\medskip





\begin{Exa} Soit $E$ un espace vectoriel de dimension $n \geq 1$. On suppose que $f \in \mathcal{L}(E)$ vérifie $f^n = \tilde{0}$ et $f^{n-1} \neq \tilde{0}$. Soit $x_0 \in E$ tel que $f^{n-1}(x_0) \neq 0_E$.

\begin{enumerate}
\item Montrer que $\mathcal{B}= (x_0, f(x_0), \ldots, f^{n-1}(x_0))$ est base de $E$. 
\item Déterminer la matrice de $f$ dans $\mathcal{B}$.
\item Soit $f$ l'application canoniquement associée à la matrice $A$ définie par :
$$ A = \begin{pmatrix}
2 & 1 & 0 \\
-3 & -1 & 1 \\
1 & 0 & -1 
\end{pmatrix}$$
Montrer que $f$ vérifie l'hypothèse de l'énoncé et déterminer un $x_0$ correspondant.
\end{enumerate}
\end{Exa}

\corr 

\begin{enumerate}
\item Montrons que $\mathcal{B}= (x_0, f(x_0), \ldots, f^{n-1}(x_0))$ est une famille libre de $E$. Soit $(\lambda_0, \ldots, \lambda_{n-1}) \in \mathbb{R}^n$ tel que :
$$ \sum_{k=0}^{n-1} \lambda_k f^k (x_0) = 0_E$$
En composant par $f^{n-1}$ qui est linéaire, et en utilisant que $f^n$ est l'endomorphisme nul de $E$, on en déduit que :
$$ \lambda_0 f^{n-1}(x_0)=0_E$$
Or par hypothèse $f^{n-1}(x_0)$ n'est pas nul donc $\lambda_0=0$. On a ainsi :
$$ \sum_{k=1}^n \lambda_k f^k (x_0) = 0_E$$
On réitère alors le procédé avec $f^{n-2}$ et de proche en proche, on obtient que pour tout $k \in \Interv{0}{n-1}$, $\lambda_k=0$. Ainsi $\mathcal{B}$ est libre et de cardinal $n$ qui est la dimension de $E$ donc $\mathcal{B}$ est une base de $E$.
\item Sachant que $f^n(x_0)=0_E$, on a :
$$ \textrm{Mat}_{\mathcal{B}}(f) = \begin{pmatrix}
0 & 0 & 0 & \cdots & 0 & 0 \\
1 & 0 & 0 & \cdots & 0 & 0 \\
0 & 1 & 0 & \cdots & 0& 0 \\
\vdots & \vdots& \ddots    & \ddots &  \vdots & \vdots \\
0 & 0 & \cdots & 1 &0 & 0\\
0 & 0 & \cdots & 0 & 1 & 0 \\
\end{pmatrix}$$

\item Par simple calcul, on a :
$$ A^2  = \begin{pmatrix}
1 & 1 & 1 \\
-2 & -2& -2 \\
1 & 1 & 1 
\end{pmatrix} \; \hbox{ et } \; A^3 = 0_3$$
Ainsi, $f^2$ n'est pas l'endomorphisme nul de $\mathbb{R}^3$ mais $f^3$ l'est. Il suffit maintenant de déterminer un vecteur $x_0$ n'appartenant pas au noyau de $A^2$. Posons $x_0= (1,0,0)$. On a :
$$ A^2 \begin{pmatrix}
1 \\
0\\
0
\end{pmatrix} = \begin{pmatrix}
1 \\
-2 \\
1
\end{pmatrix}$$
Ainsi $x_0$ n'est pas dans le noyau de $f^2$.
\end{enumerate}

\medskip

\begin{Exa} Donner les matrices, dans la base canonique, des endomorphismes suivants de $E=\mathbb{R}_n[X]$. Que peut-on en déduire concernant ces endomorphismes ?

\begin{enumerate}
\item $f : E \rightarrow E$ définie par :
$$ \forall P \in E, \; f(P) = P(X+1) $$
\item $f : E \rightarrow E$ définie par :
$$ \forall P \in E, \; f(P) = P(X+1)-P(X-1) $$
\item $f : E \rightarrow E$ définie par :
$$ \forall P \in E, \; f(P) = P-P' $$
\end{enumerate}
\end{Exa} 

\corr \begin{enumerate}
\item Soit $k \in \Interv{0}{n}$. On a (en utilisant la formule du binôme de Newton pour la deuxième égalité) : 

\begin{align*}
f(X^k) & = (X+1)^k  \\
& = \sum_{i=0}^k \binom{k}{i} X^i  
\end{align*}
Donnons la matrice de $f$ dans la base canonique de $\mathbb{R}_n[X]$ que nous noterons $\mathcal{B}$ :
$$ \textrm{Mat}_{\mathcal{B}}(f) = \begin{pmatrix}
1 &   1 & 1 &  \cdots & 1  \\
0 &  1  & 2 & \cdots &  \binom{n}{1} \\
\vdots & \vdots & \vdots & \cdots &  \vdots \\
0 &  0 & 0 &  \cdots & \binom{n-1}{n} \\
0 &  0 & 0 &  \cdots& 1 \\
\end{pmatrix}$$
La matrice de $f$ dans la base $\mathcal{B}$ est triangulaire avec des coefficients diagonaux non nuls donc elle est inversible. On en déduit que $f$ est un automorphisme de $E$. En fait, il est facile de remarquer que l'application linéaire $g : E \rightarrow E$ définie par :
$$ \forall P \in E, \; g(P) = P(X-1)$$
vérifie 
$$ g \circ f = f \circ g = \textrm{Id}_E$$
Ainsi, $g= f^{-1}$. Or on sait que :
$$ \textrm{Mat}_{\mathcal{B}}(g)= \textrm{Mat}_{\mathcal{B}}(f)^{-1} $$
Avec le même raisonnement que précédemment (en développant $(X-1)^k$ avec la formule du binôme de Newton), on en déduit que :
\begin{align*}
\textrm{Mat}_{\mathcal{B}}(f)^{-1} &  = \textrm{Mat}_{\mathcal{B}}(g) \\
& = \begin{pmatrix}
1 &   -1 & 1 &  \cdots & (-1)^n  \\
0 &  1  & -2 & \cdots &  (-1)^{n-1} \binom{n}{1} \\
\vdots & \vdots & \vdots & \cdots &  \vdots \\
0 &  0 & 0 &  \cdots & (-1)\binom{n-1}{n} \\
0 &  0 & 0 &  \cdots& 1 \\
\end{pmatrix}
\end{align*}
\item Soit $k \in \Interv{0}{n}$. On a (en utilisant la formule du binôme de Newton pour la deuxième égalité) : 

\begin{align*}
f(X^k) & = (X+1)^k - (X-1)^k \\
& = \sum_{i=0}^k \binom{k}{i} X^i - \sum_{i=0}^k \binom{k}{i} X^i (-1)^{k-i} \\
& =\sum_{i=0}^k \binom{k}{i} X^i  (1-(-1)^{k-i}) \\
& =\sum_{i=0}^{k-1} \binom{k}{i} X^i  (1-(-1)^{k-i}) 
\end{align*}
car pour $i=k$, $1-(-1)^{k-i}=0$. Donnons la matrice de $f$ dans la base canonique de $\mathbb{R}_n[X]$ que nous noterons $\mathcal{B}$ :
$$ \textrm{Mat}_{\mathcal{B}}(f) = \begin{pmatrix}
0 &   2 & 0 &  \cdots & 1-(-1)^n  \\
0 &  0  & 4 & \cdots &  (n-1) (1-(-1)^{n-1}) \\
\vdots & \vdots & \vdots & \cdots &  \vdots \\
0 &  0 & 0 &  \cdots & 2n  \\
0 &  0 & 0 &  \cdots& 0 \\
\end{pmatrix}$$
La première colonne est nulle et les autres vecteurs colonnes forment une famille libre (la matrice formée des $n$ dernières colonnes en supprimant la dernière ligne est diagonale avec des coefficients diagonaux non nuls). Ainsi, la matrice de $f$ dans la base $\mathcal{B}$ est de rang $n$ et son noyau est de dimension $1$. Alors, $f$ a un noyau de dimension $1$ et on a :
$$ \textrm{Ker}(f) = \textrm{Vect}(1) $$
La dernière ligne de la matrice de $f$ dans la base $\mathcal{B}$ est nulle donc :
$$ \textrm{Im}(f) \subset \mathbb{R}_{n-1}[X]$$
Par égalité des dimensions, on en déduit que :
$$  \textrm{Im}(f) = \mathbb{R}_{n-1}[X]$$
\item On a $f(1)=1$ et pour tout $k \in \Interv{1}{n}$, $f(X^k)=X^k-kX^{k-1}$. Ainsi, la matrice de $f$ dans la base canonique $\mathcal{B}$ de $\R_n[X]$ est : 
$$\textrm{Mat}_{\mathcal{B}}(f)=\begin{pmatrix}
1&-1&0&\cdots&0\\0&1&-2&\ddots&\vdots\\ \vdots&\ddots&\ddots&\ddots&0\\\vdots&&\ddots&\ddots&-n\\0&\cdots&\cdots&0&1
\end{pmatrix}$$
La matrice de l'endomorphisme $f$ dans la base canonique de $\R_n[X]$ est triangulaire supérieure avec des éléments diagonaux non nuls, elle est donc inversible. Ainsi, $f$ est un automorphisme de $\R_n[X]$.
\end{enumerate}


\medskip

\begin{Exa} On considère l'application $\varphi : \mathbb{R}_2[X] \rightarrow \mathbb{R}^3$ définie par :
\[ \varphi(P)=(P(0),P'(0),P(1)) \]

\begin{enumerate}
\item Déterminer la matrice de $\varphi$ dans les bases canoniques des espaces considérés.
\item Montrer que $\varphi$ est un isomorphisme d'espaces vectoriels.
\item Déterminer une expression de $\varphi^{-1}$.
\end{enumerate}
\end{Exa} 

\corr \corr \begin{enumerate}
\item La base canonique de $\mathbb{R}_2[X]$ est $\mathcal{B}=(1,X,X^2)$. On a :
\begin{itemize}
\item $\varphi(1) = (1,0,1)$.
\item $\varphi(X) = (0, 1, 1)$. 
\item $\varphi(X^2) = (0, 0, 1)$.
\end{itemize}
Ainsi, en notant $\mathcal{C}$ la base canonique de $\mathbb{R}^3$,
$$ \textrm{Mat}_{\mathcal{B}, \mathcal{C}}(\varphi) = \begin{pmatrix}
1 & 0 & 0 \\
0 & 1 & 0 \\
1 & 1 & 1 
\end{pmatrix}$$
\item La matrice de $\varphi$ dans les bases canoniques est inversible (matrice triangulaire inférieure avec des coefficients diagonaux non nuls) donc $\varphi$ est un isomorphisme d'espaces vectoriels. 

\item On sait que :
$$ \textrm{Mat}_{\mathcal{C}, \mathcal{B}}(\varphi^{-1}) = (\textrm{Mat}_{\mathcal{B}, \mathcal{C}}(\varphi))^{-1}$$
Par la méthode classique pour inverser une matrice, on a :
$$\textrm{Mat}_{\mathcal{C}, \mathcal{B}}(\varphi^{-1}) = \begin{pmatrix}
1 & 0 & 0 \\
0 & 1 & 0 \\
-1 & -1 & 1 
\end{pmatrix}$$
Soit $Z=(x,y,z) \in \mathbb{R}^3$. On sait que :
$$ \textrm{Mat}_{\mathcal{B}}(\varphi^{-1}(Z)) = \textrm{Mat}_{\mathcal{C}, \mathcal{B}}(\varphi^{-1}) \textrm{Mat}_{\mathcal{C}}(Z)$$
et ainsi :
$$ \textrm{Mat}_{\mathcal{B}}(\varphi^{-1}(Z)) = \begin{pmatrix}
1 & 0 & 0 \\
0 & 1 & 0 \\
-1 & -1 & 1 
\end{pmatrix} \begin{pmatrix}
x \\
y \\
z \\
\end{pmatrix} = \begin{pmatrix}
x \\
y \\
-x-y+z \\
\end{pmatrix}$$
En se rappelant que $\mathcal{B}=(1,X,X^2)$, on a donc :
$$ \varphi^{-1}((x,y,z)) = x + y X + (-x-y+z)X^2$$
\end{enumerate}

\medskip


\begin{Exa} Soit $E=\R^3.$

\begin{enumerate}

\item Montrer que les deux sous-espaces vectoriels suivants sont
suppl\'ementaires dans $E.$
$$F=\hbox{Vect}((1,-1,1))\quad\hbox{ et }\quad G=\{(x,y,z)\in
E,\ 2x+4y+z=0\}$$

\item D\'eterminer la matrice, dans la base canonique ${\cal B}$
de $E$, de la projection sur $G$ parallèlement à $F.$

\item En d\'eduire la matrice, dans la base ${\cal B}$, de la
sym\'etrie par rapport \`a $F$ parallèlement à $G.$
\end{enumerate}
\end{Exa} 

\corr 

\begin{enumerate}
\item Au vu de la question suivante, raisonnons par analyse-synthèse.

\medskip

\noindent \textit{Analyse.} Supposons que $E = F \oplus G$. Soit $x=(x_1,x_2,x_3) \in E$. Il existe alors un vecteur de $F$, de la forme $\alpha (1,-1,1)$, et un vecteur $(a,b,c) \in G$ tel que 
$$x = \alpha (1,-1,1) + (a,b,c)$$
Ainsi,
$$ (a,b,c) = (x_1 - \alpha, x_2+\alpha, x_3- \alpha)$$
Or $(a,b,c)$ appartient à $G$ donc $2a+4b+c=0$. Ainsi :
$$ 2(x_1 -\alpha) + 4 (x_2+ \alpha) + x_3- \alpha = 0$$
ce qui implique que :
$$ \alpha = - (2x_1+4x_2+x_3)$$

\medskip

\noindent \textit{Synthèse.} Soit $x=(x_1,x_2,x_3) \in \mathbb{R}^3$. Posons :
$$ z = \alpha (1,-1,1) \; \hbox{ où } \; \alpha = - (2x_1+4x_2+x_3)$$
et $w=x-z$. Alors $z$ appartient à $F$ (par définition) et $x=z+w$. On a :
$$ w = (x_1- \alpha, x_2+ \alpha, x_3- \alpha)$$
et 
$$ 2(x_1 - \alpha) + 4(x_2+ \alpha) + (x_3-\alpha) = 2x_1+4x_2+x_3 + \alpha = 0$$
Ainsi, $w$ appartient à $G$.

\medskip

\noindent On a donc montré que tout élément de $\mathbb{R}^3$ s'écrit comme la somme d'un élément de $F$ et d'un élément de $G$. Cette décomposition est unique d'après l'analyse. Ainsi, $F$ et $G$ sont supplémentaires dans $E$.
\item Notons $p_G$ cette projection. D'après la question précédente, en gardant les mêmes notations, on a pour tout $x \in \mathbb{R}^3$,
$$ p_G(x) = (x_1- \alpha, x_2+ \alpha, x_3- \alpha)$$
Ainsi, en notant $\mathcal{B}=(e_1,e_2,e_3)$ la base canonique de $\mathbb{R}^3$, on a :
$$ p_G(e_1) =(1 - (-2), -2, -(-2)) = (3,-2,2) $$
De même, on obtient :
$$ p_G(e_2) = (4,-3, 4) $$
et 
$$ p_G(e_3) = (1, -1, 2) $$
On obtient ainsi :
$$ \textrm{Mat}_{\mathcal{B}}(p_G) =  \begin{pmatrix}
3 & 4& 1 \\
-2& -3 & -1 \\
2 & 4 & 2
\end{pmatrix}$$
\item En notant $p_F$, la projection sur $F$ parallèlement à $G$ et $s_F$ la symétrie par rapport à $F$ parallèlement à $G$, on sait que :
$$ \textrm{Id}_E = p_F+p_G \; \hbox{ et } s_F = p_F-p_G$$
Ainsi :
$$ s_F = \textrm{Id}_E- p_G-p_G = \textrm{Id}_E - 2p_G$$
On en déduit que :
$$ \textrm{Mat}_{\mathcal{B}}(s_F) = I_3 - 2 \textrm{Mat}_{\mathcal{B}}(p_G) =  \begin{pmatrix}
-5 & -8& -2 \\
4& 7 & 2 \\
-4 & -8 & -3
\end{pmatrix}$$
\end{enumerate}


\medskip

\begin{center}
\textit{{ {\large Matrices semblables}}}
\end{center}

\medskip


\begin{Exa} Soit ${\cal B}=(e_1,e_2,e_3)$ la base canonique de $\R^3.$ On consid\`ere
l'endomorphisme $f$ de $E$ d\'efini par~:

\begin{center}
$\forall (x,y,z)\in\R^3,\quad f(x,y,z)=(x+y-z,x+2y+z,y+2z).$
\end{center}

\begin{enumerate}

\item Écrire la matrice $M$ de $f$ dans la base ${\cal B}.$

\item D\'eterminer une base de $\textrm{Ker}(f)$ et une base de $\textrm{Im}(f)$.

\item Montrer que la r\'eunion des bases pr\'ec\'edentes constitue une base de $E$. On note ${\cal B}'$ cette nouvelle base.

\item  D\'eterminer la matrice $M'$ de $f$ dans cette nouvelle base. Quel est le lien entre $M$ et $M'$ ?
\end{enumerate}

\end{Exa}

\corr 

\begin{enumerate}
\item On a :
$$ M  = \begin{pmatrix}
1  & 1 & - 1 \\
1  & 2 & 1  \\
0  & 1 & 2 \\
\end{pmatrix}$$
\item Utilisons la matrice de $M$ dans la base $\mathcal{B}=(e_1,e_2,e_3)$. L'opération $C_3 \leftarrow C_3-2C_2$ implique que la matrice de $(f(e_1),f(e_2),f(e_3-2e_2))$ dans $\mathcal{B}$ est :
$$ \begin{pmatrix}
1  & 1 & - 3 \\
1  & 2 & -3  \\
0  & 1 & 0 \\
\end{pmatrix}$$
L'opération $C_3 \leftarrow C_3+3C_1$ implique que la matrice de $(f(e_1),f(e_2),f(e_3-2e_2+3e_1))$ dans $\mathcal{B}$ est :
$$ \begin{pmatrix}
1  & 1 & 0 \\
1  & 2 & 0  \\
0  & 1 & 0 \\
\end{pmatrix}$$
La matrice obtenue est clairement de rang $2$. On en déduit que :
$$ \textrm{Ker}(f) = \textrm{Vect}((e_3-2e_2+3e_1)) = \textrm{Vect}((3,-2,1))$$
et 
$$ \textrm{Im}(f) = \textrm{Vect}((1,1,0),(1,2,1))$$
La famille $((3,-2,1))$ est une base du noyau de $f$ ($(3,-2,1)$ est non nul). De même, $((1,1,0),(1,2,1))$ est une base de l'image de $f$ car les deux vecteurs de cette famille sont non colinéaires.
\item Notons $\mathcal{B}'=((3,-2,1),(1,1,0),(1,2,1))$. Le déterminant de la famille $\mathcal{B}'$ dans la base $\mathcal{B}$ vaut :
$$ \begin{vmatrix}
3 & 1 & 1 \\
-2 & 1 & 2\\
1& 0 & 1\\
\end{vmatrix}  \underset{C_3 \leftarrow C_3 - C_1}{=} \begin{vmatrix}
3 & 1 & -2 \\
-2 & 1 & 4\\
1& 0 & 0\\
\end{vmatrix} = \begin{vmatrix}
 1 & -2 \\
 1 & 4\\
\end{vmatrix} = 6 $$
en développant par rapport à la dernière ligne. Ce déterminant étant non nul, on en déduit que $\mathcal{B}'$ est une base de $\mathbb{R}^3$.
\item Le vecteur $(3,-1,1)$ appartient au noyau de $f$ donc :
$$ f((3,-1,1))=(0,0,0)$$
Par définition de $f$, on a\footnote{Pour trouver la décomposition de l'image par $f$ de $(1,1,0)$ dans la base $\mathcal{B}'$, il suffit de remarquer que cette image appartient à l'image de $f$ qui est générée par $(1,1,0)$ et $(-2,4,0)$. On trouve ensuite facilement les coefficients (ou alors, on résout un système...).} :
$$ f((1,1,0))=(2,3,1) = (1,1,0) + (1,2,1)$$
De même,
$$ f((-2,4,0))=(2,6,4) = -2(1,1,0) + 4(1,2,1) $$
Ainsi,
$$ M' = \begin{pmatrix}
0 & 0 & 0 \\
0 & 1 & -2 \\
0 & 1 & 4 \\
\end{pmatrix}$$
Les matrices $M$ et $M'$ représentent le même endomorphisme dans des bases de $\mathbb{R}^3$ donc sont semblables.
\end{enumerate}

\medskip

\begin{Exa} Montrer que $\begin{pmatrix}
1 & 1 & -1 \\
-3 & -3 & 3 \\
-2 & -2 & 2 \\
\end{pmatrix}$ et $\begin{pmatrix}
0 & 1 & 0 \\
0 & 0 & 0 \\
0 & 0 & 0 \\
\end{pmatrix}$ sont semblables.
\end{Exa}

\corr Posons :
$$ A = \begin{pmatrix}
1 & 1 & -1 \\
-3 & -3 & 3 \\
-2 & -2 & 2 \\
\end{pmatrix} \, \hbox{ et } \,   B = \begin{pmatrix}
0 & 1 & 0 \\
0 & 0 & 0 \\
0 & 0 & 0 \\
\end{pmatrix}$$
Soit $f$ l'endomorphisme  de $\mathbb{R}^3$ canoniquement associé à la matrice $A$. On cherche une une base $\mathcal{B}'=(x_1,x_2,x_3)$ de $\mathbb{R}^3$ telle que la matrice de $f$ dans la base $\mathcal{B}'$ soit $B$. 

\medskip

\noindent \textit{Analyse.} Soit $\mathcal{B}'$ une telle base. En notant abusivement $0$ le vecteur nul de $\mathbb{R}^3$, on a alors :
$$ f(x_1)=0, \; f(x_2)=x_1 \hbox{ et } f(x_3)=0$$
Le vecteur $x_1$ est dans l'image et le noyau de $f$. Au vu de la matrice $A$, on pose :
$$ x_1 =(1,-3,-2)$$
On a :
$$ A \begin{pmatrix}
1 \\
-3 \\
-2\\
\end{pmatrix} = \begin{pmatrix}
0 \\
0 \\
0\\
\end{pmatrix}$$
Alors $f(x_1)=(0,0,0)$. De plus, en posant $x_2=(0,1,0)$, on a d'après la matrice $A$, $f(x_2)=x_1$. Posons $x_3=(0,1,1)$. Alors :
$$  A \begin{pmatrix}
0 \\
1 \\
1\\
\end{pmatrix} = \begin{pmatrix}
0 \\
0\\
0\\
\end{pmatrix}$$
Ainsi, $f(x_3)=(0,0,0)$.

\medskip

\noindent \textit{Synthèse.} Posons :
$$ x_1 =(1,-3,-2), \; x_2 = (0,1,0), \; x_3= (0,1,1)$$
D'après l'analyse, $f(x_1)=f(x_3)=(0,0,0)$ et $f(x_2)=x_1$. Montrons que $\mathcal{B}'=(x_1,x_2,x_3)$ est une base de $\mathbb{R}^3$. Le déterminant de la matrice de la famille $\mathcal{B}'$ dans la base canonique vaut (en développant par rapport à la deuxième colonne pour la première égalité) :
$$ \left\vert \begin{array}{ccc}
1 & 0 & 0 \\
-3 & 1 & 1 \\
-2 & 0 & 1 
\end{array}\right\vert =  \left\vert \begin{array}{cc} 1 & 0 \\
-2 & 1\end{array}\right\vert =1 \neq 0 $$
Ainsi, $\mathcal{B}'$ est une base de $\mathbb{R}^3$. On a de plus :
$$ \textrm{Mat}_{\mathcal{B}'}(f) = \begin{pmatrix}
0 & 1 & 0 \\
0 & 0 & 0 \\
0 & 0 & 0 \\
\end{pmatrix}$$

\medskip

\noindent Finalement, les matrices $A$ et $B$ représentent le même endomorphisme de $\mathbb{R}^3$ dans des bases différentes donc sont semblables.


\medskip

\begin{Exa} Soient $n \geq 1$ et $S : \mathcal{M}_n(\mathbb{C}) \rightarrow \mathbb{C}$ définie par :
$$ S((a_{i,j})_{1 \leq i,j \leq n}) = \sum_{1 \leq i,j \leq n} a_{i,j} a_{j,i}$$

\begin{enumerate}
\item Montrer que pour tout $(A,B) \in \mathcal{M}_n(\mathbb{C})^2$, $S(AB)=S(BA)$.
\item Montrer que deux matrices semblables ont la même image par $S$.
\end{enumerate}
\end{Exa}

\corr 

\begin{enumerate}
\item Soient $A=(a_{i,j})_{1 \leq i,j \leq n}$ et $B= (b_{i,j})_{1 \leq i,j \leq n}$  deux matrices de $\mathcal{M}_n(\mathbb{C})$. Alors :
\begin{align*}
S(AB) & =  \sum_{1 \leq i,j \leq n} (AB)_{i,j} (AB)_{j,i} \\
& = \sum_{i=1}^n \sum_{j=1}^n \left( \sum_{k=1}^n a_{i,k} b_{k,j} \right) \left( \sum_{l=1}^n a_{j,l} b_{l,i} \right) \\
& =  \sum_{i=1}^n \sum_{j=1}^n \sum_{k=1}^n \sum_{l=1}^n a_{i,k} b_{k,j} a_{j,l} b_{l,i} \\
& = \sum_{k=1}^n \sum_{l=1}^n \sum_{i=1}^n \sum_{j=1}^n b_{k,j} a_{j,l} b_{l,i} a_{i,k} \\
& = \sum_{1 \leq k,l \leq n} \sum_{i=1}^n  b_{l,i} a_{i,k}  \sum_{j=1}^n b_{k,j} a_{j,l} \\
& = \sum_{1 \leq k,l \leq n} (BA)_{l,k} (BA)_{k,l} \\
& = S(BA) 
\end{align*}
\item Soient $A$ et $B$ deux matrices semblables de $\mathcal{M}_n(\mathbb{C})$. Il existe une matrice $P \in GL_n(\mathbb{C})$ tel que :
$$ A=PBP^{-1}$$
Alors :
\begin{align*}
S(A) & = S((PB)P^{-1}) \\
& = S(P^{-1} (PB)) \; \hbox{ (d'après la question précédente)} \\
& = S(I_n B) \\
& = S(B)
\end{align*}
\end{enumerate}

\medskip

\begin{Exa} Soient $n \geq 1$ et $A$ et $B$ deux matrices \textit{réelles} semblables dans $\mathcal{M}_n(\mathbb{C})$.

\begin{enumerate}
\item Monter l'existence de deux matrices $U$, $V$ de $\mathcal{M}_n(\mathbb{R})$ telles que $AU=UB$, $AV=VB$ et $U+iV$ soit dans $GL_n(\mathbb{C})$.
\item Justifier l'existence d'un réel $a$ tel que $U+aV$ soit inversible.
\item En déduire que $A$ et $B$ sont semblables dans $\mathcal{M}_n(\mathbb{R})$.
\end{enumerate}
\end{Exa} 

\corr \begin{enumerate}
\item Les matrices $A$ et $B$ sont semblables dans $\mathcal{M}_n(\mathbb{C})$ donc il existe une matrice $P$ de $GL_n(\mathbb{C})$ tel que :
$$ A=PBP^{-1}$$
La matrice $P$ peut s'écrit sous la forme :
$$ P = U+i V$$
où $U$ et $V$ sont les matrices \og partie réelle \fg et \og partie imaginaire \fg de $P$, donc sont deux matrices de $\mathcal{M}_n(\mathbb{R})$. La matrice $U+iV$ est donc inversible car est égal à $P$. On sait que $A=PBP^{-1}$ donc $AP=PB$ ou encore :
$$ A(U+iV) = (U+iV)B$$
puis :
$$ AU+ i AV = UB + i VB$$
Par identification, on en déduit que $AU=UB$ et $AV=VB$.
\item Posons pour tout $z \in \mathbb{C}$,
$$ P(z) = \textrm{det}(A+zB)$$
Alors $P$ est une fonction polynômiale (il suffit de développer le déterminant). Or $P(i)$ est non nul car $A+iB$ est inversible. Ainsi, $P$ est une fonction polynomiale non nulle, elle admet donc une nombre fini de racines. En particulier, il existe nécessairement un réel $a$ tel que $P(a) \neq 0$ et ainsi le déterminant de $U+aV$ est non nul ce qui implique que $U+aV$ soit inversible.
\item Posons $Q=U+aV$. Alors :
\begin{align*}
AQ & = A(U+aV) \\
& = AU + a AV \\
& = UB + a VB \\
& = (U+aV)B \\
& = QB
\end{align*}
et sachant que $Q$ est inversible :
$$ A= QBQ^{-1}$$
La matrice $Q$ étant réelle (car $U$ et $V$ le sont et que $a$ est un réel), on en déduit que $A$ et $B$ sont semblables dans $\mathcal{M}_n(\mathbb{R})$.
\end{enumerate}


\medskip

\begin{center}
\textit{{ {\large Noyau, Rang}}}
\end{center}

\medskip


\begin{Exa} Donner le noyau, le rang et l'image de $A = \begin{pmatrix}
-5 & 4 & -1 \\
-4 & 3 & - 1 \\
2 	 & -2 & 0 \\
\end{pmatrix}\cdot$
\end{Exa}

\corr En notant $C_1$, $C_2$ et $C_3$ les colonnes de cette matrice, on remarque que :
$$C_1+C_2-C_3 = 0_{\mathcal{M}_{3,1}(\mathbb{R})}$$
Ainsi :
$$ \begin{pmatrix}
1 \\
1 \\
-1 
\end{pmatrix} \in \textrm{Ker}(A) $$
Donc $\textrm{dim}(\textrm{Ker}(A)) \geq 1$. Or le rang de cette matrice est supérieur ou égal à $2$ car $C_1$ et $C_2$ sont non colinéaires. D'après le théorème du rang, on a :
$$ 3=\textrm{dim}(\mathcal{M}_{3,1}(\mathbb{R})) = \textrm{dim}(\textrm{Ker}(A)) + \textrm{rg}(A)$$
et ainsi $\textrm{dim}(\textrm{Ker}(A)) = 1$ et $\textrm{rg}(A)=2$. Une base du noyau de $A$ est $\left(  \begin{pmatrix}
1 \\
1 \\
-1 
\end{pmatrix} \right)$ (c'est un vecteur non nul) et une base de l'image de $A$ est donnée par $(C_1,C_2)$ (car le rang de la matrice est $2$ et que ces deux vecteurs appartiennent à l'image et sont non colinéaires).

\medskip

\begin{Exa} Déterminer le rang de $A = \begin{pmatrix}
x & 0 & 0& y \\
y & x & 0 & 0 \\
0 & y & x & 0 \\
0 & 0 & y & x
\end{pmatrix}$ où $(x,y) \in \mathbb{R}^2$.
\end{Exa} 

\corr Distinguons plusieurs cas.

\medskip

\noindent $\rhd$ Si $(x,y)=(0,0)$, la matrice $A$ est nulle donc son rang est nul.

\medskip

\noindent $\rhd$ Si $x=0$ et $y \neq 0$. Alors :
$$ A = \begin{pmatrix}
0 & 0 & 0& y \\
y & 0 & 0 & 0 \\
0 & y & 0 & 0 \\
0 & 0 & y & 0
\end{pmatrix}$$
Les vecteurs colonnes de $A$ sont les multiples (non nuls) des vecteurs de la base canonique de $\mathcal{M}_{4,1}(\mathbb{R})$ donc le rang de $A$ est égal à $4$.

\medskip

\noindent $\rhd$ Si $x$ est non nul. L'opération $L_2 \leftarrow x L_2 - y L_1$ implique que :
$$ \textrm{rg}(A) = \textrm{rg} \left(\begin{pmatrix}
x & 0 & 0& y \\
0 & x^2 & 0 & -y^2 \\
0 & y & x & 0 \\
0 & 0 & y & x
\end{pmatrix} \right)$$
L'opération $L_3 \leftarrow x^2 L_3-y L_2$ implique que :
$$ \textrm{rg}(A) = \textrm{rg} \left(\begin{pmatrix}
x & 0 & 0& y \\
0 & x^2 & 0 & -y^2 \\
0 & 0 & x^3 & y^3 \\
0 & 0 & y & x
\end{pmatrix} \right)$$
L'opération $L_4 \leftarrow x^3 L_4-y L_3$ implique que :
$$ \textrm{rg}(A) = \textrm{rg} \left(\begin{pmatrix}
x & 0 & 0& y \\
0 & x^2 & 0 & 0 \\
0 & 0 & x^3 & 0 \\
0 & 0 & 0 & x^4-y^4
\end{pmatrix} \right)$$
Le réel $x$ étant non nul, la matrice $A$ est donc au moins de $3$ et elle est de rang $4$ si et seulement si $x^4 \neq y^4$, c'est à-dire si et seulement si $x \neq y$ et $x \neq -y$.

\medskip

\begin{Exa} Déterminer le rang de $A=(i+j+ij)_{1\leq i,j\leq n}$ pour $n \geq 2$.
\end{Exa} 

\corr Notons pour tout $j \in \Interv{1}{n}$, $C_j$, la $j$-ième colonne de $A$. Alors :
$$ C_j = \begin{pmatrix}
1 + 2j \\
2 + 3j \\
3 + 4j \\
\vdots \\
n + (n+1)j
\end{pmatrix} = \begin{pmatrix}
1  \\
2  \\
3  \\
\vdots \\
 n
\end{pmatrix} + j \begin{pmatrix}
2 \\
3 \\
4\\
\vdots \\
n+1
\end{pmatrix} \in \textrm{Vect}(X_1,X_2)$$
où 
$$ X_1= \begin{pmatrix}
1  \\
2  \\
3  \\
\vdots \\
 n
\end{pmatrix} \; \hbox{ et } \; X_2 = \begin{pmatrix}
2 \\
3 \\
4\\
\vdots \\
n+1
\end{pmatrix}$$
Ainsi, le rang de la matrice $A$ qui est égal à la dimension du sous-espace engendré par ses colonnes, est inférieur ou égal à $2$. Or les deux premières colonnes de $A$ ne sont pas colinéaires donc le rang de $A$ est supérieur ou égal à $2$. Ainsi, le rang de $A$ est égal à $2$.

\medskip


\begin{Exa} Soient $n \geq 1$ et $H \in \mathcal{M}_n(\mathbb{C})$ une matrice de rang 1.
    \begin{enumerate}
      \item
        Montrer qu'il existe des matrices $U,V \in \mathcal{M}_{n,1}(\mathbb{C})$ telles que $H = U ~^tV$.
      \item En déduire que $H^2 = \textrm{Tr}(H)H$.
 \end{enumerate}
\end{Exa}

\corr 

\begin{enumerate}
\item Notons $C_1$, $\ldots$, $C_n$ les colonnes de $H$. La matrice $H$ étant de rang $1$, il existe un vecteur colonne $C$ de $\mathcal{M}_{n,1}(\mathbb{R})$ et des scalaires $\alpha_1$, $\ldots$, $\alpha_n$ tels que :
$$ \forall i \in \Interv{1}{n}, \; C_i =\alpha_i C $$
Ainsi, on a :
$$ M = [C_1, \ldots, C_n] = [\alpha_1 C, \ldots, \alpha_n C] = C (\alpha_1, \ldots, \alpha_n) = C~^t \begin{pmatrix}
\alpha_1 \\
\vdots \\
\alpha_n
\end{pmatrix}$$
On obtient le résultat souhaité avec $U=C$ et $V = \begin{pmatrix}
\alpha_1 \\
\vdots \\
\alpha_n
\end{pmatrix} \cdot$
\item D'après la question précédente et par associativité du produit matriciel :
$$ H^2 = (U ~^tV) (U ~^tV) = U( ~^tVU )~^tV$$
Or $~^tVU$ est un réel donc :
$$ H^2 = (~^tVU ) U ~^tV =  (~^tVU ) H$$
D'après la question précédente, on a (en notant $c_i$ les composantes de $C$) :
$$ ~^tVU  = (\alpha_1, \ldots, \alpha_n) \begin{pmatrix}
c_1 \\
\vdots \\
c_n
\end{pmatrix} = \sum_{i=1}^n \alpha_i c_i $$
Or, toujours d'après la question précédente, les coefficients diagonaux de $H$ sont les réels $\alpha_i c_i$ donc $~^tVU $ est égal à la trace de $H$ et finalement, $H^2 = \textrm{Tr}(H)H$.
\end{enumerate}
 \medskip

\begin{center}
\textit{{ {\large Trace}}}
\end{center}

\medskip


\begin{Exa} Soit $n \in \mathbb{N}^*$. Existe-t-il des matrices $A,B \in \mathcal{M}_n(\mathbb{C})$ vérifiant $AB - BA = I_n$ ?
\end{Exa}

\corr Supposons l'existence de matrices $A,B \in \mathcal{M}_n(\mathbb{C})$ vérifiant $AB - BA = I_n$. Alors :
$$ \textrm{Tr}(AB-BA) = \textrm{Tr}(I_n) = n \neq 0$$
Or par linéarité de la trace et par propriété liée à la trace d'un produit :
$$  \textrm{Tr}(AB-BA) =  \textrm{Tr}(AB)- \textrm{Tr}(BA) = 0$$
C'est absurde. Ainsi, il n'existe pas de matrices $A,B \in \mathcal{M}_n(\mathbb{C})$ vérifiant $AB - BA = I_n$.

\medskip


\begin{Exa} Soient $n \geq 1$ et $A$, $B$ deux matrices de $\mathcal{M}_n(\mathbb{R})$. On suppose que pour tout $X \in \mathcal{M}_n(\mathbb{R})$, 
$$\textrm{Tr}(AX)= \textrm{Tr}(BX)$$
Montrer que $A=B$.
\end{Exa}

\corr Supposons que pour tout $X \in \mathcal{M}_n(\mathbb{R})$, 
$$\textrm{Tr}(AX)= \textrm{Tr}(BX)$$
Utilisons les matrices de la base canonique de $\mathcal{M}_n(\mathbb{R})$. Soit $(p,r) \in \Interv{1}{n}^2$. Par hypothèse,
$$ \textrm{Tr}(AE_{p,r})= \textrm{Tr}(BE_{p,r})$$
Or, pour tout $i \in \Interv{1}{n}$,
$$ (A E_{p,r})_{i,i} = \sum_{k=1}^n A_{i,k} (E_{p,r})_{k,i} $$
et $(E_{p,r})_{k,i}$ vaut $1$ si et seulement si $(p,r)=(k,i)$ et vaut $0$ sinon. Ainsi,
$$ (A E_{p,r})_{i,i} = A_{i,p} \delta_{i,r}$$
où $\delta_{i,r}$ est le symbole de Kronecker. Ainsi,
 $$ \textrm{Tr}(AE_{p,r}) = \sum_{i=1}^n (A E_{p,r})_{i,i} = A_{r,p}$$
 Le raisonnement est analogue pour $B E_{p,r}$ donc on en déduit que :
 $$ A_{r,p}= B_{r,p}$$
 Ceci étant vrai pour tout $(p,r) \in \Interv{1}{n}^2$, on en déduit que $A=B$.



\medskip

\begin{center}
\textit{{ {\large Déterminant}}}
\end{center}

\medskip


\begin{Exa} Peut-on trouver une matrice $A \in \mathcal{M}_3(\mathbb{R})$ telle que $A^2= - I_3$?
\end{Exa}

\corr Supposons par l'absurde l'existence d'une $A \in \mathcal{M}_3(\mathbb{R})$ telle que $A^2= - I_3$. Alors :
$$ \textrm{det}(A^2) = \textrm{det}(-I_3) = - 1$$
et donc 
$$ \textrm{det}(A)^2 = \textrm{det}(-I_3) = - 1$$
Or $\textrm{det}(A)$ est un réel donc son carré est un nombre positif : c'est absurde. Ainsi, il n'existe pas de matrice $A \in \mathcal{M}_3(\mathbb{R})$ telle que $A^2= - I_3$.

\medskip

\begin{Exa} Soient $n \geq 1$, $\lambda_1 ,\lambda_2 ,\ldots,\lambda_n$ des réels et $a$, $b$ deux réels distincts. On pose pour tout $x \in \mathbb{R}$,
    \[
    \Delta_n(x) =
    \begin{vmatrix}
        {\lambda_1 + x} & {a + x} & \cdots & {a + x} \\
        {b + x} & {\lambda_2 + x} & \ddots & \vdots \\
        \vdots & \ddots & \ddots & {a + x} \\
        {b + x} & \cdots & {b + x} & {\lambda_n + x} \\
    \end{vmatrix}    
    \]
    \begin{enumerate}
      \item Montrer que $\Delta_n$ est une fonction affine.
      \item Donner son expression.
    \end{enumerate}
\end{Exa}

\corr 

\begin{enumerate}
\item Soit $x \in \mathbb{R}$. En utilisant les opérations $C_i \leftarrow C_i - C_1$ pour tout $i \in \Interv{2}{n}$, on a :
    \[
    \Delta_n(x) =
    \begin{vmatrix}
        {\lambda_1 + x} & a - \lambda_1 & \cdots & a- \lambda_1 \\
        {b + x} & \lambda_2-b & \ddots & \vdots \\
        \vdots & \ddots & \ddots & a-b \\
        {b + x} & \cdots & 0 & \lambda_n-b \\
    \end{vmatrix}    
    \]
En développant par rapport à la première colonne, $\Delta_n(x)$ est égal à :
$$ (\lambda_1+x) K_1 - (b+x) K_2 + (b+x) K_3 + \cdots + (-1)^{n+1} (b+x) K_n$$
Où $K_1$, $\ldots$, $K_n$, sont des déterminants de taille $n-1$ ne dépendant pas de $x$ donc constants. Ainsi, $\Delta_n$ est une fonction affine car somme de fonctions affines.
\item D'après la question précédente, il existe deux réels $p$ et $q$ tels que pour tout $x \in \mathbb{R}$,
$$ \Delta_n(x) = px + q$$
En reprenant l'expression de départ de $\Delta_n$, on remarque que $\Delta_n(-a)$ et $\Delta_n(-b)$ sont des déterminants triangulaires et sont donc faciles à calculer :
$$ \Delta_n(-a) = \prod_{k=1}^n \lambda_k - a \; \hbox{ et } \Delta_n(-b) = \prod_{k=1}^n \lambda_k - b$$
Les réels $-a$ et $-b$ sont différents donc on obtient la pente facilement :
$$ p = \dfrac{\Delta_n(-a) - \Delta_n(-b)}{-a-(-b)} = \dfrac{\Delta_n(-a) - \Delta_n(-b)}{b-a}$$
puis on a :
$$ q = \Delta_n(-a) -pa$$
\end{enumerate}

\medskip

\begin{Exa} Soient $n \geq 2$ et $f \in \mathcal{L}(\mathcal{M}_n(\mathbb{R}))$ définie par $f(M) = \dfrac{M+~^tM}{2}\cdot$

\begin{enumerate}
\item Donner, sans aucun calcul, le déterminant de $f$.
\item Déterminer le noyau, l'image et le rang de $f$. 
\end{enumerate}
\end{Exa}

\corr

\begin{enumerate}
\item Pour tout $M \in \mathcal{M}_n(\mathbb{R})$, $f(M)$ est une matrice symétrique. Or, il existe des matrices non symétriques dans $\mathcal{M}_n(\mathbb{R})$ car $n \geq 2$. Ainsi, $f$ n'est pas surjective et donc n'est pas bijective. Le déterminant de $f$ est donc nul.
\item Soit $M \in \mathcal{M}_n(\mathbb{R})$. Alors :
\begin{align*}
M \in \textrm{Ker}(f) & \Longleftrightarrow f(M)=0_n \\
& \Longleftrightarrow M+~^tM= 0_n \\
& \Longleftrightarrow ~^tM=-M 
\end{align*}
Ainsi, le noyau de $f$ est l'ensemble des matrices antisymétriques. D'après le cours, on en déduit que :
$$ \textrm{dim}(\textrm{Ker}(f)) = \dfrac{n(n-1)}{2}$$
L'espace vectoriel $\mathcal{M}_n(\mathbb{R})$ est de dimension $n^2$. D'après le théorème du rang, on en déduit que :
$$ \textrm{rg}(f) = n^2 - \dfrac{n(n-1)}{2} = \dfrac{n(n+1)}{2}$$
Dans la question $1$, on a montré que :
$$ \textrm{Im}(f) \subset \mathcal{S}_n(\mathbb{R})$$
Ces espaces sont de même dimension donc sont égaux.

\medskip

\noindent \textit{Remarque.} On peut aussi aller beaucoup plus vite en remarquant que $f$ est la projection vectorielle sur $\mathcal{S}_n(\mathbb{R})$ parallèlement à $\mathcal{A}_n(\mathbb{R})$ (connaitre parfaitement la décomposition d'une matrice en somme d'une matrice symétrique et d'une matrice antisymétrique est très important).
\end{enumerate}

\medskip

\begin{Exa} Déterminer pour tout entier $n \geq 1$, le déterminant $D_n$ de taille $n$ suivant :

\[
    D_n =
    \begin{vmatrix}
        2 & 1 & {} & {(0)} \\
        1 & \ddots & \ddots & {} \\
        {} & \ddots & \ddots & 1 \\
        {(0)} & {} & 1 & 2 \\
    \end{vmatrix}_{[n]}
    \]
\end{Exa} 

\corr On a $D_1=2$ et 
$$ D_2 = \begin{vmatrix}
2 & 1 \\
1 & 2 
\end{vmatrix} = 3$$
Déterminons une relation de récurrence. Soit $n \geq 1$. On développant par rapport à la première colonne, on a :
\begin{align*}
D_{n+2} & = 2  \begin{vmatrix}
        2 & 1 & {} & {(0)} \\
        1 & \ddots & \ddots & {} \\
        {} & \ddots & \ddots & 1 \\
        {(0)} & {} & 1 & 2 \\
    \end{vmatrix}_{[n+1]} - \, \begin{vmatrix}
        1 & 0 & 0 & \cdots & 0 \\
        1 & 2 & 1 & \cdots & 0  \\
        0 & 1 & 2 & \cdot & 0 \\
        0 & &\ddots  & \ddots & 1 \\
        0 & 0 & & 1 & 2 \\
    \end{vmatrix}_{[n+1]}
\end{align*}
et en développant par rapport à la première ligne le deuxième déterminant :
\begin{align*}
D_{n+2} & = 2  \begin{vmatrix}
        2 & 1 & {} & {(0)} \\
        1 & \ddots & \ddots & {} \\
        {} & \ddots & \ddots & 1 \\
        {(0)} & {} & 1 & 2 \\
    \end{vmatrix}_{[n+1]} -  \,\begin{vmatrix}
        2 & 1 & {} & {(0)} \\
        1 & \ddots & \ddots & {} \\
        {} & \ddots & \ddots & 1 \\
        {(0)} & {} & 1 & 2 \\
    \end{vmatrix}_{[n]}  = 2 D_{n+1} - D_n 
\end{align*}
La suite $(D_n)_{n \geq 1}$ est donc récurrente linéaire d'ordre deux. Son équation caractéristique, $x^2-2x+1=0$, admet pour unique solution $1$. Il existe donc deux réels $\lambda$ et $\mu$ tels que pour tout entier $n \geq 1$,
$$ D_n = (\lambda+ \mu n) 1^n = \lambda + \mu n$$
Or $D_1=2$ donc $\lambda+\mu =2$. De même, $D_2=3$ donc $\lambda+ 2 \mu = 3$. La première équation donne $\lambda = 2- \mu$ ce qui implique grâce à la deuxième :
$$  2- \mu + 2 \mu = 3$$
et ainsi $ \mu =1$ puis $\lambda=1$. Ainsi, pour tout entier $n \geq 1$,
$$ D_n = 1+n$$

\medskip


\begin{Exa} Soient $a_1 ,a_2 , \ldots ,a_n \in \mathbb{C}$. Calculer :
    \[
    \begin{vmatrix}
        {a_1} & {a_2} & \cdots & {a_n} \\
        {} & \ddots & \ddots & \vdots \\
        {} & {} & \ddots & {a_2} \\
        {(a_1)} & {} & {} & {a_1} \\
    \end{vmatrix}
    \]
\end{Exa}

\corr Les opérations successives $L_k \leftarrow L_k - L_{k-1}$ pour $k=n$, $k=n-1$, $\ldots$, $k=2$ implique que le déterminant cherché vaut :
$$  \begin{vmatrix}
        {a_1} & {a_2} & \cdots & a_{n-1} & {a_n} \\
        0 &  a_1-a_2 & \cdots & & a_{n-1}-a_n \\
         0& 0& \ddots & & \vdots\\
        \vdots & \vdots & \ddots& a_1-a_2 & {a_2-a_3} \\
        0 & 0 & \cdots  & 0& {a_1-a_2} \\
    \end{vmatrix} = a_1 (a_1-a_2)^{n-1}$$
 car ce déterminant est triangulaire.




\end{document}