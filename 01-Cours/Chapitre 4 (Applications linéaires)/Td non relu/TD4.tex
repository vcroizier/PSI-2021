\documentclass[a4paper,10pt]{report}
\usepackage{cours}

\begin{document}
\everymath{\displaystyle}

\begin{center}
 \shadowbox{{\huge TD 4 : Applications linéaires}}
\end{center}

\bigskip



\begin{Exercice}{} Soient $n \geq 1$ et $a_{0} ,a_{1} , \ldots ,a_{n}$ des éléments deux à deux distincts de $\mathbb{C}$. Montrer que l'application $\varphi \colon \mathbb{C}_n[X] \rightarrow \mathbb{C}^{n+1}$ définie par
  \[
  \varphi(P) = (P(a_{0}),P(a_{1}), \ldots ,P(a_{n}))
  \]
  est un isomorphisme.
\end{Exercice}

\corr Soient $P,Q \in \mathbb{C}_n[X]$ et $\lambda \in \mathbb{C}$. Alors :
\begin{align*}
\varphi(\lambda P + Q ) & = ((\lambda P+Q)(a_{0}),(\lambda P+Q)(a_{1}), \ldots , (\lambda P+Q)(a_{n})) \\
& = \lambda (P(a_{0}),P(a_{1}), \ldots ,P(a_{n})) + (Q(a_{0}),Q(a_{1}), \ldots ,Q(a_{n})) \\
& = \lambda \varphi(P) + \varphi(Q)
\end{align*}
Ainsi, $\varphi$ est linéaire.

\medskip

\noindent Soit $P \in \mathbb{C}_n[X]$. Si $P$ appartient au noyau de $\varphi$ alors :
$$ P(a_0) = P(a_1) = \cdots = P(a_n) = 0$$
Ainsi, $P$ admet $n+1$ racines distinctes et a un degré inférieur ou égal à $n$ donc $P$ est le polynôme nul. Ainsi,
$$ \textrm{Ker}(\varphi) \subset \lbrace \tilde{0} \rbrace$$
L'autre inclusion est vraie car le noyau de $\varphi$ est un sous-espace vectoriel de $\mathbb{C}_n[X]$. Ainsi, $\varphi$ est injective. Or :
$$ \textrm{dim}(\mathbb{C}_n[X]) = \textrm{dim}(\mathbb{C}^{n+1}) = n+1$$
Donc $\varphi$ est un isomorphisme.


\begin{Exercice}{} Soient $\mathbb{K}= \mathbb{R}$ ou $\mathbb{C}$ et $\varphi : \mathbb{K}_{n+1}[X]\rightarrow \mathbb{K}_{n}[X]$ définie par $\varphi(P) = (n + 1)P - XP'$.
    \begin{enumerate}
      \item
        Justifier que $\varphi$ est bien définie et que c'est une application linéaire.
      \item
        Déterminer le noyau de $\varphi$.
      \item
        $\varphi$ est-elle surjective?
    \end{enumerate}
\end{Exercice}

\corr \begin{enumerate}
\item Soit $P \in \mathbb{K}_{n+1}[X]$. Il est clair que $\varphi(P)$ est un polynôme à coefficients dans $\mathbb{K}$. On a :
\begin{align*}
\textrm{deg}((n+1)P -XP') & \leq  \textrm{max}(\textrm{deg}(P), \textrm{deg}(XP')) \\
& \leq  \textrm{max}(\textrm{deg}(P), 1 +\textrm{deg}(P') ) \\
 &\leq  \textrm{deg}(P) 
\end{align*}
Cet argument n'est pas suffisant pour conclure. Procédons autrement\footnote{Pour justifier qu'une application linéaire entre deux espaces de polynômes est bien définie, on utilise souvent un argument lié au degré : il est très important de connaitre les propriétés liées au degré d'une somme, d'un produit, d'une composée... Si cela ne suffit pas : il peut être utile de déterminer explicitement l'expression de l'application.} : Il existe $(a_0, \ldots, a_{n+1}) \in \mathbb{K}^{n+2}$ tel que :
$$ P = \sum_{k=0}^{n+1} a_k X^k $$
Ainsi :
\begin{align*}
\varphi(P) & = \sum_{k=0}^{n+1} (n+1) a_k X^k - X \sum_{k=1}^{n+1} k a_k X^{k-1}  \\
& = (n+1)a_0  + \sum_{k=1}^{n+1} (n+1-k)a_k X^k  \\
& = (n+1)a_0 + \sum_{k=1}^{n} (n+1-k)a_k X^k  
\end{align*} 
car le coefficient de $X^{n+1}$ est nul. Ainsi, le degré de $P$ est inférieur ou égal à $n$. Donc $\varphi(P) \in \mathbb{K}_n[X]$ et $\varphi$ est bien définie.

\medskip

\noindent Montrons que $\varphi$ est linéaire. Soient $(P,Q) \in \mathbb{K}_{n+1}[X]^2$ et $\lambda \in \mathbb{R}$. On a :

\begin{align*}
\varphi(\lambda P + Q) & = (n+1)(\lambda P+Q)-X(\lambda P + Q)' \\
& = \lambda (n+1)P + (n+1)Q - \lambda X P' - XQ' \quad \hbox{par linéarité de la dérivation} \\
& = \lambda ((n+1)P-XP') + (n+1)Q-XQ' \\
& = \lambda \varphi(P) + \varphi(Q) 
\end{align*}
Ainsi $\varphi$ est linéaire.
\item Soit $P \in \mathbb{K}_{n+1}[X]$. Il existe $(a_0, \ldots, a_{n+1}) \in \mathbb{K}^{n+2}$ tel que :
$$ P = \sum_{k=0}^{n+1} a_k X^k $$
On a, en notant $\theta$ le polynôme nul, et d'après la question précédente : 
\begin{align*}
P \in \textrm{Ker}(\varphi) & \Longleftrightarrow  \varphi(P) = \theta \\
& \Longleftrightarrow (n+1) a_0 + \sum_{k=1}^n (n+1-k) a_k X^k =\theta  \\
\end{align*}
Et ainsi, par identification, $P \in \textrm{Ker}(\varphi)$ si et seulement si $a_0 = \cdots = a_n = 0$ (car pour tout $k \in \Interv{0}{n}$, $(n+1-k) \neq 0$). Finalement $P$ appartient au noyau si et seulement si $P = a_{n+1} X^{n+1}$ et donc $\textrm{Ker}(\varphi)= \textrm{Vect}(X^{n+1})$.
\item La dimension de $\mathbb{K}_{n+1}[X]$ est $n+2$ et celle du noyau de $\varphi$ est $1$ (d'après la question précédente sachant que $X^{n+1}$ n'est pas nul). D'après le théorème du rang, le rang de $\varphi$ est $n+1$ qui est la dimension de $\mathbb{K}_n[X]$ (l'espace d'arrivée de $\varphi$). Ainsi, $\varphi$ est surjective.
\end{enumerate}



\begin{Exercice}{} Soient $E= \mathbb{R}^3$ et $F$, $G$ les ensembles définis par :
$$ F = \lbrace (x,y,z) \in \mathbb{R}^3, \, x-y+z=0 \rbrace \quad \hbox{ et }  \quad G = \textrm{Vect}((1,1,1)) $$

\begin{enumerate}
\item Donner une base de $F$ et préciser sa dimension.
\item Montrer que $F$ et $G$ sont supplémentaires.
\item Soit $p$ la projection sur $F$ parallèlement à $G$. Donner l'expression de $p$.
\item Soit $q$ la projection sur $G$ parallèlement à $F$. Donner l'expression de $q$.
\end{enumerate}
\end{Exercice}

\corr  

\begin{enumerate}
\item Soit $(x,y,z) \in \mathbb{R}^3$. On a :
$$ (x,y,z) \in F \Longleftrightarrow x=y-z \Longleftrightarrow (x,y,z) = (y-z,y,z) \Longleftrightarrow (x,y,z) = y(1,1,0) + z(-1,0,1)$$
Ainsi $F = \textrm{Vect}((1,1,0), (-1,0,1))$ (donc les vecteurs $(1,1,0)$ et $(-1,0,1)$ forment une famille génératrice de $F$). De plus, ces deux vecteurs sont non colinéaires donc forment une famille libre de $F$ et ainsi forment une base de $F$. La dimension de $F$ est donc $2$.
\item On sait que $\textrm{dim}(F)=2$ et $\textrm{dim}(G)=1$ (car $(1,1,1)$ est non nul). Ainsi $\textrm{dim}(F) + \textrm{dim}(G) = \textrm{dim}(\mathbb{R}^3)$. Il nous suffit alors de montrer que $F \cap G = \lbrace (0,0,0) \rbrace$. Soit $(x,y,z) \in F \cap G$. Il existe $\alpha \in \mathbb{R}$ tel que $(x,y,z) = \alpha (1,1,1)$ et sachant que $x-y+z=0$, on obtient $\alpha = 0$ puis $(x,y,z)=(0,0,0)$. Ainsi $F \cap G \subset \lbrace (0,0,0) \rbrace$ et l'autre inclusion est vérifiée car $F$ et $G$ sont des sous-espaces vectoriels de $\mathbb{R}^3$.

\medskip

\noindent Les espaces $F$ et $G$ sont donc des sous-espaces vectoriels supplémentaires de $\mathbb{R}^3$.
\item D'après la question précédente, $F$ et $G$ sont  des sous-espaces vectoriels supplémentaires de $\mathbb{R}^3$. Soit $(x,y,z) \in \mathbb{R}^3$. Il existe $x_F = (a,b,c) \in F$ et $x_G \in G$ tel que $(x,y,z) = x_F + x_G$. Par définition de $G$, il existe $\alpha \in \mathbb{R}$ tel que $x_G = (\alpha, \alpha, \alpha)$. Ainsi :
$$ (x,y,z) = (a,b,c) + (\alpha, \alpha, \alpha)$$
Or $x_F \in F$ donc $a-b+c=0$ et ainsi $x- \alpha- y + \alpha + z - \alpha = 0$ puis finalement :
$$ \alpha = x-y+z $$
Ainsi $x_G = (x-y+z) (1,1,1)$ et $x_F = (x,y,z) - x_G = (y-z, -x+2y-z,-x+y)$. Par définition de la projection sur $F$ parallèlement à $G$, on a donc pour tout $(x,y,z) \in \mathbb{R}^3$,
$$ p((x,y,z)) = (y-z, -x+2y-z,-x+y)$$

\medskip

\noindent \textit{Remarque.} On peut avec la méthode proposée ici montrer en une fois que $F$ et $G$ sont des sous-espaces vectoriels supplémentaires de $\mathbb{R}^3$ et d'obtenir la décomposition associée de chaque élément de $\mathbb{R}^3$ : il suffit de raisonner par analyse-synthèse (qui donne la décomposition et l'unicité de celle-ci).
\item D'après la question précédente, on a pour tout $(x,y,z) \in \mathbb{R}^3$, 
$$ q((x,y,z)) = (x-y+z) (1,1,1)$$

\medskip

\noindent \textit{Remarque.} On a $p+q=\textrm{Id}$.
\end{enumerate}

\begin{Exercice}{}
\begin{enumerate}
\item Soit $u$ un endomorphisme d'un espace vectoriel $E$ de dimension $n \geq 1$.
\begin{enumerate}
\item On suppose $u$ injectif. Déterminer pour tout $m \geq 1$, $K_m = \textrm{Ker}(u^m)$ et $I_m = \textrm{Im}(u^m)$.
\item Montrer que pour tout $m \geq 0$, $K_m \subset K_{m+1}$ et $I_{m+1} \subset I_m$.
\item On suppose $u$ non injectif. Montrer l'existence d'un entier $p \in \Interv{1}{n}$ tel que $K_p=K_{p+1}$ et $I_p = I_{p+1}$.

\noindent Montrer alors que pour tout $q \in \mathbb{N}$, $K_p = K_{p+q}$ et $I_p = I_{p+q}$ puis que $E = K_p \oplus I_p$.
\end{enumerate}
\end{enumerate}
\end{Exercice} 

\corr \begin{enumerate}
\item Par hypothèse, $u$ est un endomorphisme injectif d'un espace vectoriel de dimension finie donc $u$ est un automorphisme et par composition, $u^m$ aussi pour tout $m \geq 1$. Ainsi, $K_m =\lbrace 0_E \rbrace$ et $I_m = E$.
\item Soit $m \geq 0$.
\begin{itemize}
\item Soit $x \in E$. Si $x \in K_m$ alors $f^m(x)=0_E$ donc par linéarité de $f$ :
$$ f(f^m(x))=f(0_E)=0_E$$
donc $f^{m+1}(x)=0_E$ et ainsi $x \in K_{m+1}$. Ainsi, $K_m \subset K_{m+1}$.
\item Soit $x \in E$. Si $x \in I_{m+1}$ alors il existe $z \in E$ tel que $x = f^{m+1}(z)$ et donc $x= f^m(f(z))$ avec $f(z) \in E$ donc $x \in I_m$. Ainsi, $I_{m+1} \subset I_m$.
\end{itemize}

\item Supposons par l'absurde que pour tout $p \in \Interv{0}{n}$, $K_p \neq K_{p+1}$. D'après la question précédente, on en déduit que :
$$ K_0 \subset K_1 \subset \cdots \subset K_{n+1} \subset E$$
et chaque inclusion est stricte donc :
$$ 0 \leq \textrm{dim}(K_0) < \textrm{dim}(K_1) < \cdots < \textrm{dim}(K_{n+1}) \leq n$$
On obtient ainsi $n+2$ entiers distincts compris entre $0$ et $n$ ce qui est absurde. Ainsi, il existe un entier $p \in \Interv{0}{n}$ tel que $K_p=K_{p+1}$. 

\medskip

\noindent L'autre propriété se démontre exactement de la même manière.

\medskip

\noindent Montrons par récurrence que pour tout $q \in \mathbb{N}$, $K_p = K_{p+q}$. La propriété est évidente au rang $0$. Soit $q \in \mathbb{N}$ tel que $K_p= K_{p+q}$. Montrons que $K_p=K_{p+q+1}$. On sait déjà que $K_p \subset K_{p+q+1}$. Soit $x \in  K_{p+q+1}$. Alors $f^{p+q+1}(x)=0_E$ donc $f^{p+q}(f(x))=0_E$ et ainsi $f(x)$ appartient à $K_{p+q}$ et donc à $K_p$ par hypothèse de récurrence. Ainsi $f^{p}(f(x))=0_E$ donc $f^{p+1}(x)=0_E$ ce qui implique que $x$ appartient à $K_{p+1}$ qui est égal à $K_p$ par définition de $p$. On a donc $K_{p+q+1} \subset K_p$ et donc l'égalité.

\medskip

\noindent La propriété est donc vraie au rang $0$ et est héréditaire donc est vraie pour tout $q \geq 0$.

\medskip

\noindent On sait que pour tout $q \geq 0$, $I_p \subset I_{p+q}$. D'après le théorème du rang, on a :
$$ \textrm{dim}(I_p) = \textrm{dim}(E) - \textrm{dim}(K_p)$$
et 
$$ \textrm{dim}(I_{p+q}) = \textrm{dim}(E) - \textrm{dim}(K_{p+q})$$
Or $K_p = K_{p+q}$ d'après le raisonnement précédent donc $I_p$ et $I_{p+q}$ ont la même dimension et $I_p \subset I_{p+q}$ donc ces espaces sont égaux.

\medskip

\noindent Montrons maintenant que $E = K_p \oplus I_p$. D'après le théorème du rang, il suffit de vérifier que $K_p$ et $I_p$ sont en somme directe. On sait que $\lbrace 0_E \rbrace \subset  K_p \oplus I_p$ car $K_p$ et $I_p$ sont des sous-espaces vectoriels de $E$. Soit $x \in  K_p \oplus I_p$. Alors $f^p(x)=0_E$ et il existe alors $z \in E$ tel que $x=f^p(z)$. On en déduit que $f^{2p}(z)=0_E$ donc $z \in K_{2p}$ et d'après la question précédente, $z \in K_p$. Finalement $x=f^p(z)=0_E$ et l'inclusion souhaitée est démontrée.

\end{enumerate}


\begin{Exercice}{} Soient $E= \mathbb{R}_n[X]$ et $L \in \mathcal{L}(E, \mathbb{R})$ définie par :
$$ \forall P \in E, \;  L(P) = \int_{-1}^1 P(t) \dt$$
\begin{enumerate}
\item Déterminer l'image de $P= \sum_{k=0}^n a_k X^k$ par $L$.
\item Déterminer la dimension puis une base du noyau de $L$.
\item Soit $(x_0, x_1, \ldots, x_n) \in \mathbb{R}^n$ tels que $-1 \leq x_0 < x_1 < \cdots < x_n \leq 1$. Montrer que pour tout $i \in \Interv{0}{n}$, il existe un unique polynôme $P_i$ de $E$ tel que pour tout $j \in \Interv{0}{n}$, $P_i(x_j)= \delta_{i,j}$.
\item Montrer que $(P_0, \ldots, P_n)$ est une base de $E$.
\item Montrer qu'il existe $(\lambda_0, \ldots, \lambda_n) \in \mathbb{R}^{n+1}$ tel que :
$$ \forall P \in E, \; \int_{-1}^1 P(t) \dt = \lambda_0 P(x_0) + \cdots + \lambda_n P(x_n)$$
\end{enumerate}
\end{Exercice}

\corr \begin{enumerate}
\item Par linéarité de $L$, on a :
\begin{align*}
L(P) & = \sum_{k=0}^n a_k \int_{-1}^{1} x^k \dx \\
& = \sum_{0 \leq k \hbox{ {\scriptsize pair}} \leq n} \dfrac{2a_k}{k+1} 
\end{align*}
\item L'application $L$ est une forme linéaire non nulle ($L(1)=2$) sur l'espace vectoriel $\mathbb{R}_n[X]$ qui est de dimension $n+1$ donc le noyau de $L$ est un hyperplan de cet espace et est donc de dimension $n$.

\medskip

\noindent Soit $\dis P= \sum_{k=0}^n a_k X^k$. D'après la question précédente, $P$ appartient au noyau de $L$ si et seulement si :
$$ a_0 = - \sum_{2 \leq k \hbox{ {\scriptsize pair}} \leq n} \dfrac{2a_k}{k+1}$$
Si $n$ est pair : il existe $p \geq 1$ tel que $n=2p$. Dans ce cas, l'égalité précédente se réécrit :
$$ a_0 = - \dfrac{2a_2}{3} - \dfrac{2a_4}{5} - \cdots - \dfrac{2a_{2p}}{2p+1}$$
Ainsi, $P$ appartient au noyau de $L$ si et seulement si :
\begin{align*}
P(X) & =  - \dfrac{2a_2}{3} - \dfrac{2a_4}{5} - \cdots - \dfrac{2a_{2p}}{2p+1} + \sum_{k=1}^n a_k X^k \\
& = a_1 X + a_2 \left(X^2   - \dfrac{2}{3} \right) + a_3 X^3 +  a_4 \left(X^4   - \dfrac{2}{5} \right) + \cdots +  a_{2^p} \left(X^{2p}   - \dfrac{2}{2p+1} \right)
\end{align*}
Ainsi,
$$ \textrm{Ker}(L) = \textrm{Vect} \left(X,X^2   - \dfrac{2}{3},X^3,X^4   - \dfrac{2}{5}, \ldots, X^{2p}   - \dfrac{2}{2p+1} \right)$$
La famille générant cet espace est de cardinal $n=2p$ qui est la dimension du noyau donc c'est une base de celui-ci. Dans le cas où $n=2p+1$, on obtient :
$$ \textrm{Ker}(L) = \textrm{Vect} \left(X,X^2   - \dfrac{2}{3},X^3,X^4   - \dfrac{2}{5}, \ldots, X^{2p}   - \dfrac{2}{2p+1}, X^{2p+1} \right)$$
ce qui donne une base pour les mêmes raisons.
%\item Soit $(x_0, x_1, \ldots, x_n) \in \mathbb{R}^n$ tels que $-1 \leq x_0 < x_1 < \cdots < x_n \leq 1$. Posons :
%$$ P_i(X) = \prod_{k \in \Interv{1}{n} \setminus \lbrace i \rbrace} \dfrac{X-x_k}{x_i-x_k}$$
%où pour tout $k \in \Interv{1}{n}$,
%$$ L_k(X) = \prod_{r \in \Interv{1}{n} \setminus \lbrace k \rbrace} \dfrac{X-x_r}{x_k- x_r}$$
%Le polynôme $P$ est une somme de polynômes de degré $n-1$ donc est bien de degré au plus $n-1$ et vérifie pour tout $j \in \Interv{1}{n}$ que $P_i(x_j)= a_i$ car (de manière usuelle) $L_i(x_k) = \delta_{i,k}$.
\item L'application $f : E \rightarrow \mathbb{R}^{n+1}$ définie par :
$$ f(P) = (P(x_0), \ldots, P(x_n))$$
est une application linéaire. Son noyau est réduit au polynôme nul car si un polynôme $P$ de $E$ appartient à son noyau alors il admet $n+1$ racines distinctes et a un degré inférieur ou égal à $n$ donc il est nul. Ainsi $f$ est une application linéaire injective. Or la dimension de $E$ est égal à la dimension de $\mathbb{R}^{n+1}$ donc $f$ est un isomorphisme. Ainsi tout élément de $\mathbb{R}^{n+1}$ admet un unique antécédent par $f$. On obtient le résultat en appliquant ce résultat à tout élément de la base canonique de $\mathbb{R}^{n+1}$.
\item Cette famille contient $n+1$ éléments qui est la dimension de $E$. Il suffit de montrer que cette famille est libre. Soit $(\lambda_0, \lambda_1, \ldots, \lambda_n) \in \mathbb{R}^{n+1}$ tel que :
$$ \sum_{i=0}^n \lambda_i P_i (X)= 0$$
En évaluant, pour $k \in \Interv{0}{n}$, en $x_k$, on obtient (en utilisant la question précédente) que :
$$ \lambda_k =0$$
Ainsi, $(P_0, \ldots, P_n)$ est une famille libre et donc une base de $E$.
\item Supposons l'existence de $(\lambda_0, \ldots, \lambda_n) \in \mathbb{R}^{n+1}$ tel que :
$$ \forall P \in E, \; \int_{-1}^1 P(t) \dt = \lambda_0 P(x_0) + \cdots + \lambda_n P(x_n)$$
En particulier, pour tout $k \in \Interv{0}{n}$,
$$ \int_{-1}^1 P_k(t) \dt = \lambda_0 P_k(x_0) + \cdots + \lambda_n P_k(x_n)$$
et donc :
$$ \lambda_k =  \int_{-1}^1 P_k(t) \dt$$
Ainsi, si ce $n$-uplet existe, il est unique. Posons $\varphi : E \rightarrow \mathbb{R}$ définie par :
$$  \forall P \in E, \;  \varphi(P)= \lambda_0 P(x_0) + \cdots + \lambda_n P(x_n)$$
où les $\lambda_k$ sont définis comme précédemment. Alors $\varphi$ est une forme linéaire sur $E$ et $\varphi$ et $L$ coïncident sur la base $(P_0, \ldots, P_n)$ donc elles sont égales. Ainsi, pour tout $P \in E$,
$$ \int_{-1}^1 P(t) \dt = \lambda_0 P(x_0) + \cdots + \lambda_n P(x_n)$$
\end{enumerate}

\begin{Exercice}{} \begin{enumerate}
 \item Montrer que l'ensemble $V$ des suites complexes défini par :
 $$ V = \lbrace (v_n)_{n \geq 0} \, \vert \, \forall n \geq 0, \; v_{n+3}=v_{n+2}+v_n \rbrace$$
est un $\C$-espace vectoriel.
 \item Montrer que $P(X)=X^3-X^2-1$ admet une unique racine réelle et deux racines complexes conjuguées.
 \item Montrer que $\phi : V \rightarrow \mathbb{C}^3$ définie par :
 $$ \phi(v)=(v_0,v_1,v_2)$$
  définit un isomorphisme de $V$ dans $\C^3$ et en déduire la dimension de $V$.
 \item Trouver les suites géométriques de $V$ et en déduire une base de $V$.
\end{enumerate}
\end{Exercice}

\corr \begin{enumerate}
 \item Utilisons la méthode des trois points.
 \begin{itemize}
 \item $V \subset \mathbb{C}^{\mathbb{N}}$.
 \item La suite nulle appartient à $V$.
 \item Soit $(u,v)\in V^2$ et soit $\lambda\in\C$. Posons $w=u + \lambda v$. Pour tout $n\in\N$, 
 \begin{align*}
 w_{n+3} & =u_{n+3}+\lambda v_{n+3} \\
 & =u_{n+2}+u_n+\lambda(v_{n+2}+v_n) \; \hbox{ car } \; (u,v)\in V^2 \\
 & =(u_{n+2}+\lambda v_{n+2})+(u_n+\lambda v_n) \\
 & =w_{n+2}+\lambda w_n
 \end{align*}
 Ainsi, $w \in V$. 
 \end{itemize}
Ainsi, $V$ est un sous-espace vectoriel de $\C^\N$.
 \item On confond polynôme et fonction polynômiale. On a $P'(X)=3X^2-2X=(3X-2)X$.
 \begin{itemize}
\item $P$ est continue sur $]-\infty,0[$, pour tout $x \in ]-\infty,0[$,
$$ P'(x) = (3x-2)x>0$$
donc $P$ est strictement croissante sur $]-\infty,0[$. D'après le théorème de bijection, $P$ est une bijection de $]-\infty,0[$ sur 
$$ P(]-\infty,0[)=  ]\lim_{x \rightarrow - \infty} P(x), \lim_{x \rightarrow 0^{-}} P(x)[=   ]-\infty,-1[$$
Ainsi, $P$ ne s'annule pas sur$]-\infty,0[$ donc $P$ n'admet pas de racines appartenant à $]-\infty,0[$.
\item On obtient de la même manière que $P$ ne s'annule pas sur $[0, 2/3]$.
\item Toujours de la même manière, on montre que $P$ est une bijection de $]2/3, + \infty[$ sur $]-31/27,+\infty[$. $0$ appartient à $]-31/27,+\infty[$ donc $P$ s'annule une unique fois sur $]2/3, + \infty[$.
\end{itemize}
Ainsi, $P$ possède une unique racine réelle $\alpha$ strictement plus grande que $2/3$. Cette racine est simple car $P'$ s'annule uniquement en $0$ et $2/3$ et $\alpha$ est strictement plus grande que $2/3$. D'après le théorème fondamental de l'algèbre, $P$ admet trois racines complexes donc $P$ admet une unique racine réelle et deux racines complexes non réelles. Le polynôme $P$ étant à coefficients réels, les racines complexes non réelles sont conjuguées. Nous noterons dans la suite $r_0$ la racine réelle et $r_1$ et $r_2$ les racines complexes conjuguées.
 \item Montrons que $\phi$ est linéaire. Soient $(u,v)\in V^2$ et $\lambda\in\C$. Alors :
 \begin{align*}
\phi(u+\lambda v) & =(u_0+\lambda v_0,u_1+\lambda v_1,u_2+\lambda v_2) \\
& =(u_0,u_1,u_2)+\lambda(v_0,v_1,v_2) \\
=\phi(u)+\lambda\phi(v)
\end{align*}
Montrons que $\phi$ est injective. Soit $v \in V$ tel que $\phi(v)=(0,0,0)$. Alors :
$$ v_1=v_2=v_3=0$$
Montrons par récurrence triple pour tout entier $n \geq 0$, $v_n=0$. La propriété est vraie pour $n=1$, $2$ et $3$. Soit $n \in \mathbb{N}$ tel que :
$$ v_n=v_{n+1}=v_{n+2} = 0$$
On sait que $v \in V$ donc :
$$ v_{n+3}=v_{n+2}+v_n = 0 $$
La propriété est donc vraie au rang $n+3$. Ainsi, par principe de récurrence, on en déduit que $v$ est nulle. Ainsi, $\textrm{Ker}(\phi) \subset \lbrace \theta \rbrace$ ($\theta$ est la suite nulle). L'autre inclusion est vérifiée car le noyau de $\phi$ est un sous-espace vectoriel de $\mathbb{C}^{\mathbb{N}}$. Ainsi, $\phi$ est injective.


\medskip

\noindent L'application $\phi$ est surjective par construction (on définit $(v_n)$ par $v_0=a$, $v_1=b$, $v_2=c$ et pour tout $n\in\N$, $v_{n+3}=v_{n+2}+v_n$, ainsi $v$ est dans $V$ par construction et $\phi(v)=(a,b,c)$). 

\medskip


\noindent Finalement, $\phi$ est un isomorphisme et ainsi $\dim V=3$
 \item Il suffit, par stabilité par multiplication par un scalaire, de déterminer les suites de la forme $(q^n)_{n \geq 0}$ appartenant à $V$. Excluons le cas $q=0$ (suite nulle à partir du rang $1$). Soit $q\in\C^\star$. Alors :
 \begin{align*}
(q^n)\in V & \Longleftrightarrow \forall n\in\N, \; q^{n+3}=q^{n+2}+q^n \\
&\Longleftrightarrow \forall n\in\N, \; q^n q^3=q^{n}q^{2}+q^n \\
&\Longleftrightarrow \forall n\in\N, \; q^3=q^{2}+1 \hbox{ car } q \neq 0 \\
&\Longleftrightarrow  q^3=q^{2}+1 \hbox{ car } q \neq 0 \\
&\Longleftrightarrow P(q)=0 \\
&\Longleftrightarrow q= r_0 \hbox{ ou } q=r_1 \hbox{ ou } q=r_2
\end{align*}
Montrons que la famille $((r_0^n),(r_1^n),(r_2^n))$ est libre. Soit $(\alpha,\beta,\gamma)\in\C^3$ tels que pour tout $n\in\N$, $\alpha r_0^n+\beta r_1^n+\gamma r_2^n=0$. Les raisons étant non nuls, on a :
$$\left\lbrace\begin{array}{rcl} \alpha+\beta+\gamma&=&0 \\ \alpha r_0+\beta r_1+\gamma r_2&=&0 \\\alpha r_0^2+\beta r_1^2+\gamma r_2^2&=&0\end{array}  \right.$$
On utilise les opérations $L_i\leftarrow L_i-r_0L_{i-1}$ pour $i=2$ et $i=1$ :
$$\left\lbrace\begin{array}{rcl} \alpha+\beta+\gamma&=&0 \\ \beta (r_1-r_0)+\gamma (r_2-r_0)&=&0 \\  \beta r_1(r_1-r_0)+\gamma r_2(r_2-r_0) &=&0\end{array}  \right.$$
On fait ensuite l'opération $L_3\leftarrow L_3-r_1L_2$ : 
$$\left\lbrace\begin{array}{rcl} \alpha+\beta+\gamma&=&0 \\ \beta (r_1-r_0)+\gamma (r_2-r_0)&=&0 \\  \gamma (r_2-r_1)(r_2-r_0) &=&0\end{array}  \right.$$ 
Sachant que $(r_2-r_1)(r_2-r_0)\neq0$ on trouve $\gamma=0$, par suite comme $r_1-r_0\neq 0$ on trouve $\beta=0$ puis $\alpha=0$, ce qui termine de montrer que la famille est libre. Cette famille est donc une famille libre de $V$, de cardinal $3$ qui est la dimension de $V$ donc c'est une base de $V$. Ainsi,
$$V=\textrm{Vect}((r_0^n),(r_1^n),(r_2^n))$$

\medskip

\noindent On peut résoudre le système plus simplement avec un déterminant de Vandermonde. En effet, le premier système est équivalent à :
$$ \begin{pmatrix}
1 & 1 & 1 \\
r_0 & r_1 & r_2 \\
r_0^2 & r_1^2 & r_2^2 \\
\end{pmatrix} \begin{pmatrix}
\alpha \\
\beta \\
\gamma
\end{pmatrix} = \begin{pmatrix}
0 \\
0 \\
0 \\
\end{pmatrix}$$ 
Le déterminant de la matrice $3 \times 3$ vaut :
$$ \prod_{0 \leq i <j \leq 2} (r_j-r_i) = (r_2-r_1)(r_2-r_0)(r_1-r_0) \neq 0$$
Cette matrice est donc inversible, son noyau est réduit au vecteur nul donc on retrouve que :
$$ \alpha = \beta = \gamma = 0$$
\end{enumerate}

\begin{Exercice}{} Soit $f$ une forme linéaire sur $E$, $\mathbb{R}$-espace vectoriel de dimension $n$, et $a\in E$ tel que $f(a)\neq 0$.
\begin{enumerate}
\item Montrer que $E=\textrm{Ker}(f)\oplus\textrm{Vect}(a)$.
\item On suppose $f(a)=1$. Montrer que $p : E \rightarrow E$ définie pour tout $x \in E$, par :
$$ p(x) = f(x) a $$
est un projecteur et donner les sous-espaces $F$ et $G$ tels que $p$ soit le projecteur sur $F$ parallèlement à $G$.
\end{enumerate}
\end{Exercice}

\corr 

\begin{enumerate}
\item L'application $f$ est une forme linéaire non nulle (car $f(a) \neq 0$) donc son noyau est un hyperplan de $E$ donc de dimension $n-1$. L'espace vectoriel $\textrm{Vect}(a)$ est de dimension $1$ car $a$ est non nul (son image par $f$ est non nulle). Pour montrer que le noyau de $f$ et $\textrm{Vect}(a) sont supplémentaires$, il suffit de montrer que l'intersection de ces deux espaces est réduite au vecteur nul. On sait déjà que $\lbrace 0_E \rbrace \subset \textrm{Ker}(f) \cap \textrm{Vect}(a)$ car le noyau de $f$ et $\textrm{Vect}(a)$ sont des sous-espaces vectoriels de $E$. Soit $x \in \textrm{Ker}(f) \cap \textrm{Vect}(a)$. Il existe $\lambda \in \mathbb{R}$ tel que $x= \lambda a$. Par linéarité de $f$, on a :
$$ f(x) = \lambda f(a)$$
Or $x$ est dans le noyau de $f$ donc $f(x) = 0$ et donc $\lambda f(a) = 0$. Or $f(a)$ n'est pas nul donc $\lambda$ l'est et $x$ est donc le vecteur nul. Ainsi, $\textrm{Ker}(f) \cap \textrm{Vect}(a) \subset \lbrace 0_E \rbrace$ et la double inclusion est vérifiée.
\item L'application $p$ est linéaire car $f$ l'est. Pour tout $x \in E$, on a :
$$ p \circ p (x) = p(f(x) a) = f(x) p(a)$$
car $p$ est linéaire. Ainsi,
$$ p \circ p (x) = f(x) f(a) a = f(x) a = p(x)$$
car $f(a)=1$. Ainsi, $p \circ p$ donc $p$ est un projecteur sur $F= \textrm{Im}(p)= \textrm{Ker}(p- \textrm{Id}_E)$ parallèlement à $G = \textrm{Ker}(p)$. Pour tout $x \in E$,
$$ p(x) = f(x) a \in \textrm{Vect}(a)$$
Donc $\textrm{Im}(p) \subset \textrm{Vect}(a)$. Or $p$ est non nulle ($p(a)=f(a) a= a \neq 0_E$) donc son image est au moins de dimension $1$. De plus, $\textrm{Vect}(a)$ est de dimension $1$ donc on en déduit que :
$$ F = \textrm{Vect}(a)$$
Soit $x \in E$. On a :
$$ x \in G \Longleftrightarrow p(x) = 0_E \Longleftrightarrow f(x) a = 0_E \Longleftrightarrow f(x) = 0_E$$
car $a$ est non nul. Ainsi,
$$ x \in G \Longleftrightarrow x \in \textrm{Ker}(f)$$
et donc 
$$ G = \textrm{Ker}(f)$$
\end{enumerate}

\begin{Exercice}{} Soient $E$ un $\mathbb{K}$-espace vectoriel et $f \in \mathcal{L}(E)$ tel que :
    \[
    f^2 - 3f + 2 \textrm{Id}_E = \theta
    \]
où $\theta$ est l'endomorphisme nul de $E$.
    \begin{enumerate}
      \item Montrer que $f$ est bijective et donner sa bijection réciproque.
      \item Montrer que $\textrm{Ker}(f - \textrm{Id}_E)$ et $\textrm{Ker}(f - 2\textrm{Id}_E)$ sont des sous-espaces vectoriels supplémentaires de $E$.
    \end{enumerate}
\end{Exercice}

\corr 

\begin{enumerate}
\item D'après l'hypothèse, on a :
$$ f^2-3f =  2 \textrm{Id}_E$$
Ainsi, par linéarité de $f$,
$$ f \circ (f-3 \textrm{Id}_E) = 2 \textrm{Id}_E$$
et toujours par linéarité de $f$:
$$ f \circ \left( \dfrac{f-3 \textrm{Id}_E}{2} \right) = \textrm{Id}_E$$
On a aussi :
$$ (f- 3 \textrm{Id}_E) \circ f = 2 \textrm{Id}_E$$
Par linéarité de $f- 3 \textrm{Id}_E$, on a donc :
$$ \left( \dfrac{f-3 \textrm{Id}_E}{2} \right) \circ f = \textrm{Id}_E$$
Ainsi, en posant $g = \dfrac{f-3 \textrm{Id}_E}{2}$, on a :
$$f \circ g = g \circ f = \textrm{Id}_E$$
$f$ est donc un automorphisme de $E$ et on a :
$$ f^{-1} = \dfrac{f-3 \textrm{Id}_E}{2}$$
\item Raisonnons par analyse-synthèse.

\medskip

\noindent \textit{Analyse.} Supposons que :
$$\textrm{Ker}(f - \textrm{Id}_E) \oplus \textrm{Ker}(f - 2\textrm{Id}_E) = E$$
Soit $x \in E$. Il existe $(y,z) \in \textrm{Ker}(f - \textrm{Id}_E) \times \textrm{Ker}(f - 2\textrm{Id}_E)$ tel que $x=y+z$. Par linéarité de $f$, on a :
$$f(x) = f(y) + f(z) = y+2z$$
On obtient donc le système suivant :
$$ \left\lbrace \begin{array}{rcl}
 y+z & = x \\
y+2z & = f(x)\\
\end{array}\right.$$
L'opération $L_2 \leftarrow L_2- L_1$, implique que $z = f(x)-x$. En utilisant $L_1$, on a :
$$ y= x-z = x -(f(x)-x)= 2x-f(x)$$

\medskip

\noindent \textit{Synthèse.} Soit $x \in E$. Posons :
$$ y= 2x-f(x) \; \hbox{ et } \; z= f(x)-x$$
On a $y+z=x$. Montrons que $y$ appartient à $\textrm{Ker}(f - \textrm{Id}_E)$ :
\begin{align*}
(f - \textrm{Id}_E)(2x-f(x)) & = f(2x-f(x))- (2x-f(x)) \\
& = 2f(x) -f^2(x)-2x+f(x) \hbox{ car } f \in \mathcal{L}(E) \\
&  &- f^2(x) +3f(x) -2x \\
& = 0_2
\end{align*}
car $f^2 - 3f + 2 \textrm{Id}_E = \theta$. On montre de même que $z$ appartient à $\textrm{Ker}(f - 2\textrm{Id}_E)$.

\medskip

\noindent Finalement, tout vecteur de $E$ s'écrit comme la somme d'un élément de $\textrm{Ker}(f - \textrm{Id}_E)$ et de$\textrm{Ker}(f - 2\textrm{Id}_E)$. De plus, cette décomposition est unique d'après l'analyse. Ainsi, $\textrm{Ker}(f - \textrm{Id}_E)$ et $\textrm{Ker}(f - 2\textrm{Id}_E)$ sont des sous-espaces vectoriels supplémentaires de $E$.
\end{enumerate}

\begin{Exercice}{} Pour tout $P \in \mathbb{R}_3[X]$, on pose $\varphi(P)$ le reste de la division euclidienne de $(X^4-1)P$ par $X^4-X$. Montrer que $\varphi$ définit ainsi une endomorphisme de $\mathbb{R}_3[X]$ puis déterminer son noyau et son image.
\end{Exercice} 

\corr 

\noindent $\rhd$ Soit $P\in \mathbb{R}_3[X]$. Le reste de la division euclidienne de $(X^4-1)P$ par $X^4-X$ est un polynôme à coefficients réels de degré strictement inférieur au degré de $X^4-X$. C'est un donc un polynôme de $\mathbb{R}_3[X]$. Ainsi, pour tout $P \in \mathbb{R}_3[X]$, $\varphi(P) \in \mathbb{R}_3[X]$.

\medskip

\noindent $\rhd$ Montrons que $\varphi$ est linéaire. Soient $(P,Q) \in \mathbb{R}_3[X]^2$ et $\lambda \in \mathbb{R}$. D'après le théorème de division euclidienne, il existe deux uniques couples $(P_1,P_2)$ et $(Q_1,Q_2)$ de polynômes tels que :
$$ (X^4-1)P(X) = P_1(X)(X^4-X)+ P_2(X) \; \hbox{ et } \; (X^4-1)Q(X) = Q_1(X)(X^4-X)+ Q_2(X)$$
et vérifiant $\textrm{deg}(P_2(X))<4$ et $\textrm{deg}(Q_2(X))<4$. Par définition,
$$ \varphi(P)= P_2 \; \hbox{ et } \; \varphi(Q) = Q_2$$
D'après les relations précédentes, on a :
$$ (X^4-1)(P(X) + \lambda Q(X))  = (P_1(X)+ \lambda Q_1(X))(X^4-X) + (P_2(X)+ \lambda Q_2(X))$$
Or on a :
$$ \textrm{deg}(P_2(X)+ \lambda Q_2(X)) \leq \max(\textrm{deg}(P_2(X)), \textrm{deg}(\lambda Q_2(X))<4$$
Par unicité de de la division euclidienne, on en déduit alors que $P_2(X)+ \lambda Q_2(X)$ est le reste de la division euclidienne de $(X^4-1)(P+ \lambda Q)$ par $X^4-X$. Ainsi,
 $$\varphi(P + \lambda Q) = P_2(X)+ \lambda Q_2(X) = \varphi(P) + \lambda \varphi(Q)$$

\noindent 

\noindent $\rhd$ Déterminons le noyau de $\varphi$. Soit $P \in \mathbb{R}_3[X]$. Alors $P$ appartient au noyau de $\varphi$ si et seulement si le reste de la division euclidienne de $(X^4-1)P(X)$ par $(X^4-X)$ est nul. C'est équivalent au fait que $X^4-X$ divise le polynôme $(X^4-1)P(X)$ ou encore à l'existence d'un polynôme $Q$ à coefficients réels tel que :
$$ X(X-1)(X-j)(X-j^2) Q(X) = (X-1)(X+1)(X-i)(X+i) P(X)$$
Si un tel polynôme $Q$ existe, cela implique que $0$, $j$ et $j^2$ sont des racines de $(X-1)(X+1)(X-i)(X+i) P(X)$ et donc de $P$. Or $P$ est de degré inférieur ou égal à $3$ donc il existe un réel $\lambda$ tel que :
$$ P(X) = \lambda X (X-j)(X-j^2) = \lambda X (X^2+X+1)$$
Réciproquement si $P(X) = \lambda X (X-j)(X-j^2)$ avec $\lambda \in \mathbb{R}$ alors :
$$ (X-1)(X+1)(X-i)(X+i) P(X) = \lambda (X-1)(X+1)(X-i)(X+i) X (X-j)(X-j^2) = X(X-1)(X-j)(X-j^2) Q(X)$$
avec $Q(X) = \lambda (X+1)(X-i)(X+i) = \lambda(X+1)(X^2+1) \in \mathbb{R}$. Finalement, on a :
$$ \textrm{Ker}(\varphi) = \textrm{Vect}(X(X^2+X+1))$$

\medskip

\noindent L'espace $\mathbb{R}_3[X]$ est de dimension $4$ et le noyau de $\varphi$ est de dimension $1$ car $X(X^2+X+1)$ est non nul. D'après le théorème du rang, on en déduit que l'image de $\varphi$ est de dimension $3$. Il suffit de trouver trois vecteurs de l'image formant une famille libre pour obtenir une base de l'image. Remarquons que :
$$ \left\lbrace \begin{array}{l}
(X^4-1) \times 1 = X^4-X + X-1 \\
(X^4-1) \times X = (X^4-X) \times X + X^2-X\\
(X^4-1) \times X^2 = (X^4-X) \times X^2 + X^3-X^2\\
\end{array}\right.$$
et les polynômes $X-1$, $X^2-X$ et $X^3-X^2$ ont un degré strictement plus petit que $4$. Par unicité dans le théorème de division euclidienne, on en déduit que :
$$ \varphi(1)= X-1, \; \varphi(X)= X^2-X \; \hbox{ et } \; \varphi(X^3) = X^3-X^3$$
Les polynômes $X-1$, $X^2-X$ et $X^3-X^2$ sont non nuls et sont échelonnés  en degré donc forment une famille libre à $3$ éléments. Cette famille est donc une base de l'image de $\varphi$ :
$$ \textrm{Im}(\varphi) = \textrm{Vect}(X-1,X^2-X,X^3-X^2)$$

\begin{Exercice}{} Soient $p,q$ deux endomorphismes d'un espace vectoriel $E$. Montrer que les assertions suivantes sont équivalentes :
    \begin{enumerate}
\item $p \circ q = p$ et $q \circ p = q$.
\item $p$ et $q$ sont des projecteurs de même noyau.
    \end{enumerate}
\end{Exercice}

\corr Raisonnons par double implications.

\medskip

\noindent $\rhd$. Supposons que $p \circ q = p$ et $q \circ p = q$.  Alors :
\begin{align*}
p^2 & = (p \circ q) \circ (p \circ q) \\
&=p \circ (q \circ p) \circ q \; \hbox{ par associativité} \\
& =p \circ q \circ q  \; \hbox{ car } q \circ p = q\\
&=  p \circ q \; \hbox{ car } p \circ q = p\\
& = p \; \hbox{ car }  p\circ q = p
\end{align*}
Par un argument symétrique, on montre que $q^2=q$. Ainsi, $p$ et $q$ sont des projecteurs.

\medskip

\noindent Soit $x \in E$. Si $x$ appartient au noyau de $p$ alors $p(x) = 0_E$ donc par linéarité de $q$ :
$$ q(x)= q \circ p(x) = q(p(x))=q(0_E) = 0_E$$
Donc $x$ appartient au noyau de $q$. Par un argument symétrique, on montre que si $x$ appartient au noyau de $q$, il appartient au noyau de $p$. Ainsi, $p$ et $q$ ont le même noyau.

\medskip

\noindent $\rhd$. Supposons que $p$ et $q$ sont des projecteurs de même noyau. Alors :
$$ E = \textrm{Ker}(p) \oplus \textrm{Im}(p) = \textrm{Ker}(q) \oplus \textrm{Im}(q)$$
Montrons que $p \circ q= q$. Soit $x \in E$. Il existe un unique couple $(y,z) \in \textrm{Ker}(q) \oplus \textrm{Im}(q)$ tel que $x=y+z$. Alors :
\begin{align*}
p \circ q(x) & = p\circ q (y+z) \\
& = p (q(y)+q(z))  \; \hbox{ car } q \in \mathcal{L}(E) \\
& = p (q(z))   \; \hbox{ car } y \in \textrm{Ker}(q) \\
& = p(z) \hbox{ car } z \in \textrm{Im}(q)
\end{align*}
et 
\begin{align*}
p(x) & = p(y+z) \\
& = p(y)+p(z) \; \hbox{ car } p \in \mathcal{L}(E) \\
& =  p(z) \; \hbox{ car } y \in \textrm{Ker}(q) = \textrm{Ker}(p)
\end{align*}
Ainsi, pour tout $x \in E$, $p \circ q(x)=p(x)$ donc $p \circ q = p$. Un argument symétrique donne $q \circ p = q$.

\begin{Exercice}{} Soient $u$, $v$ deux endomorphismes d'un $\mathbb{K}$-espace vectoriel $E$. On suppose que $u$ et $v$ commutent. Montrer que $\textrm{Ker}(u)$ et $\textrm{Im}(u)$ sont stables par $v$.
\end{Exercice} 

\corr 

\noindent $\rhd$ Montrons que $\textrm{Ker}(u)$ est stable par $v$, c'est-à-dire :
$$ \forall x \in \textrm{Ker}(u), \; v(x) \in \textrm{Ker}(u)$$
Soit $x \in \textrm{Ker}(u)$. Alors :
\begin{align*}
u (v(x)) & = u \circ v (x) \\
& = v \circ u (x) \; \hbox{ car } u \circ v = v \circ u \\
& = v(u(x)) \\
& = v(0_E) \; \hbox{ car } x \in \textrm{Ker}(u) \\
& = 0_E \; \hbox{ car } v \in \mathcal{L}(E)
\end{align*}
Ainsi, $v(x) \in \textrm{Ker}(u)$. On a bien montré le résultat souhaité.

\medskip

\noindent $\rhd$ Montrons que $\textrm{Im}(u)$ est stable par $v$, c'est-à-dire :
$$ \forall y \in \textrm{Im}(u), \; v(y) \in \textrm{Im}(u)$$
Soit $y \in \textrm{Im}(u)$. Il existe $x \in E$ tel que $y = u(x)$. Ainsi :
\begin{align*}
v(y) & = v (u(x)) \\
& = v \circ u(x) \\
& = u \circ v(x) \; \hbox{ car } u \circ v = v \circ u \\
& = u (v(x)) 
\end{align*}
avec $v(x) \in E$. Ainsi, $v(y) \in \textrm{Im}(u)$. On a a donc montré le résultat souhaité.


\begin{Exercice}{} Soit $E$ un $\mathbb{K}$-espace vectoriel de dimension finie supérieure ou égale à 2. Soient $H_1$ et $H_2$ deux hyperplans de $E$ distincts. Déterminer la dimension de $H_1 \cap H_2$.
\end{Exercice}

\corr Les espaces $H_1$ et $H_2$ ont pour dimension $n-1$. On a :
$$ H_1 \cap H_2 \subset H_1$$
Ainsi, 
$$ \textrm{dim}(H_1 \cap H_2) \leq  \textrm{dim}(H_1) = n-1$$
Raisonnons par l'absurde en supposant que $\textrm{dim}(H_1 \cap H_2) = n-1$ alors par inclusion et égalité des dimensions, on a :
$$ H_1 \cap H_2 = H_1$$
donc $H_1 \subset H_2$ et par égalité des dimension, on en déduit que $H_1 = H_2$ ce qui est absurde d'après l'énoncé. Ainsi,
$$  \textrm{dim}(H_1 \cap H_2) \leq n-2$$
D'après la formule de Grassmann, on sait que :
$$  \textrm{dim}(H_1 + H_2) =  \textrm{dim}(H_1)  +  \textrm{dim}(H_2) -  \textrm{dim}(H_1 \cap H_2) $$
donc 
$$  \textrm{dim}(H_1 \cap H_2) =  \textrm{dim}(H_1)  +  \textrm{dim}(H_2) -  \textrm{dim}(H_1 + H_2) $$
et ainsi :
$$\textrm{dim}(H_1 \cap H_2) =  2n-2 -  \textrm{dim}(H_1 + H_2) $$
$H_1+H_2$ est un sous-espace vectoriel de $E$ donc au plus de dimension $n$. Ainsi,
$$\textrm{dim}(H_1 \cap H_2) =  2n-2 -  \textrm{dim}(H_1 + H_2) \geq 2n-2-n = n-2$$
Finalement, on en déduit que :
$$ \textrm{dim}(H_1 \cap H_2) =  n-2 $$


\begin{Exercice}{} Soient $E$ un $\mathbb{K}$-espace vectoriel et $f \in \mathcal{L}(E)$.

\begin{enumerate}
\item On suppose que pour tout $x \in E$, $(x, f(x))$ est liée.
\begin{enumerate}
\item Montrer que pour tout $x \in E$, il existe $\lambda_x \in \mathbb{K}$ tel que $f(x)= \lambda_x x$.
\item Montrer que pour tous $x,y \in E$, non nuls, on a $\lambda_x = \lambda_y$. \textit{On pourra commencer par le cas où $(x,y)$ est une famille liée.}
\item En déduire que $f$ est une homothétie vectorielle.
\end{enumerate}
\item Déterminer les endomorphismes $f$ de $\mathcal{L}(E)$ commutant avec tous les endomorphismes.
\end{enumerate}
\end{Exercice} 

\corr 
\begin{enumerate}
\item On suppose que pour tout $x \in E$, $(x, f(x))$ est liée.
\begin{enumerate}
\item Soit $x \in E$. La famille $(x, f(x))$ est liée donc il existe un couple de scalaires $(\alpha, \beta) \neq (0,0)$ tel que :
$$ \alpha x + \beta f(x) = 0_E$$
Si $\beta=0$ alors $\alpha \neq 0$ donc $x$ est nul. Dans ce cas, $f(x)=0_E$ et il suffit de poser $\lambda_x=0$. Si $\beta$ est non nul, on a :
$$ f(x) = - \dfrac{\alpha}{\beta} x$$
Il suffit dans ce cas de poser $\lambda_x = - \dfrac{\alpha}{\beta} \cdot$
\item Soit $(x,y) \in E^2$ tel que $x$ et $y$ soient non nuls.

\medskip

\noindent $\rhd$. Supposons que $(x,y)$ est liée. Les vecteurs étant non nuls, il existe donc un scalaire $\mu$ tel que :
$$ x = \mu y$$
Par linéarité de $f$, on a :
$$ f(x) = \mu f(y)$$
et ainsi :
$$ \lambda_x x = \mu \lambda_y  y$$
puis sachant que $x= \mu y$ :
$$ \lambda_x x = \lambda_y  x$$
Le vecteur $x$ est non nul donc $\lambda_x = \lambda_y$.

\medskip

\noindent $\rhd$ Supposons que $(x,y)$ est libre. On sait que :
$$ f(x+y) = \lambda_{x+y} (x+y) = \lambda_{x+y} x + \lambda_{x+y} y$$
Par linéarité de $f$, on a aussi :
$$ f(x+y) = f(x) + f(y) = \lambda_x x + \lambda_y y$$
Ainsi,
$$ \lambda_{x+y} x + \lambda_{x+y} y = \lambda_x x + \lambda_y y$$
puis :
$$ (\lambda_{x+y}- \lambda_x) x + (\lambda_{x+y}-\lambda_y) y =0_E$$
La famille $(x,y)$ étant libre, on en déduit que $\lambda_{x+y}- \lambda_x=0$ et $\lambda_{x+y}- \lambda_y=0$ donc $\lambda_x= \lambda_y$.
\item D'après la question précédente, il existe un scalaire $\lambda$ tel que pour tout vecteur $x$ de $E$ non nul,
$$ f(x)= \lambda x$$
Cette égalité est vraie pour $x=0_E$. On en déduit que $f$ est une homothétie vectorielle.
\end{enumerate}
\item Raisonnons par analyse-synthèse.

\medskip

\noindent \textit{Analyse.} Soit $f$ de $\mathcal{L}(E)$ commutant avec tous les endomorphismes. Tentons d'utiliser la question précédente. Soit $x \in E$. Montrons l'existence d'un scalaire $\lambda_x$ tel que $f(x)= \lambda_x x$. C'est évident si $x=0_E$. Supposons $x$ non nul. L'espace $F= \textrm{Vect}(x)$ est de dimension $1$. $F$ admet un supplémentaire $G$. Considérons $p$ la projection sur $F$ parallèlement à $G$. D'après l'hypothèse,
$$ f \circ p = p \circ f$$
En particulier,
$$ f \circ p (x) = p \circ f(x)$$
Or $p(x)=x$ car $x$ est dans l'image de $p$. De plus, $p \circ f(x)$ est par définition dans l'image de $p$ qui est $\textrm{Vect}(x)$ donc il existe un scalaire $\lambda_x$ tel que $p \circ f(x) = \lambda_x x$. Ainsi,
$$ f(x) = \lambda_x x$$
D'après la question précédente, on en déduit que $f$ est une homothétie vectorielle.

\medskip

\noindent Soit $f$ une homothétie vectorielle de $E$. Il existe un scalaire $\lambda$ tel que pour tout $x \in E$, $f(x)= \lambda x$. Montrons que $f$ commute avec tout endomorphisme de $E$. Soit $g \in \mathcal{L}(E)$. On a :
$$ g \circ f(x) = g (f(x)) = g(\lambda x)= \lambda g(x)$$
car $g$ est une application linéaire. On a aussi :
$$ f \circ g(x) = \lambda g(x)$$
On en déduit que pour tout $x \in E$,
$$ g \circ f(x) = f \circ g(x)$$
Ainsi, $f$ commute avec $g$.
\end{enumerate}

\begin{Exercice}{} Soient $E$ un $\mathbb{K}$-espace vectoriel de dimension finie et $f \in \mathcal{L}(E)$. Montrer que :
$$ \textrm{rg}(f^2 ) =  \textrm{rg}( f ) \, \Longleftrightarrow E = \textrm{Ker}(f) \oplus \textrm{Im}(f) $$
\end{Exercice}

\corr Raisonnons par double implications.

\medskip

\noindent $\rhd$ Supposons que $\textrm{rg}(f^2 ) =  \textrm{rg}( f )$. D'après le théorème du rang, on sait que :
$$ \textrm{dim}(E) = \textrm{dim}( \textrm{Ker}(f)) + \textrm{rg}( f )$$
Pour montrer que le noyau et l'image de $f$ sont supplémentaires dans $E$, il suffit de montrer que ces espaces sont en somme directe. D'après l'hypothèse, $\textrm{rg}(f^2 ) =  \textrm{rg}( f )$. D'après le théorème du rang, on a :
$$ \textrm{dim}( \textrm{Ker}(f)) + \textrm{rg}( f ) = \textrm{dim}( \textrm{Ker}(f^2)) + \textrm{rg}( f^2)$$
donc 
$$ \textrm{dim}( \textrm{Ker}(f)) = \textrm{dim}( \textrm{Ker}(f^2))$$
Or le noyau de $f$ est inclus dans le noyau de $f^2$ donc ces espaces sont égaux.

\medskip

\noindent On sait que $\lbrace 0_E \rbrace \subset \textrm{Ker}(f) \cap \textrm{Im}(f)$. Soit $x \in E$. Supposons que $x \in \textrm{Ker}(f) \cap \textrm{Im}(f)$. Alors il existe un vecteur $y$ de $E$ tel que $x=f(y)$ et $f(x)=0_E$ donc $f^2(y)=0_E$. Ainsi, $y$ appartient au noyau de $f^2$ qui est égal au noyau de $f$ donc $x=f(y)=0_E$. Ainsi, $\textrm{Ker}(f) \cap \textrm{Im}(f) \subset \lbrace 0_E \rbrace$ et finalement l'égalité souhaitée est prouvée.


\medskip

\noindent $\rhd$ Supposons que $E = \textrm{Ker}(f) \oplus \textrm{Im}(f)$. Montrons que le rang de $f^2$ est égal au rang de $f$, c'est-à-dire :
$$ \textrm{dim}(\textrm{Im}(f^2)) = \textrm{dim}(\textrm{Im}(f))$$
On sait que $\textrm{Im}(f^2) \subset \textrm{Im}(f)$. Il suffit donc de montrer que $\textrm{Im}(f) \subset \textrm{Im}(f^2)$. Soit $y \in \textrm{Im}(f)$. Il existe un vecteur $x$ de $E$ tel que $y=f(x)$. D'après l'hypothèse, il existe un unique couple $(z,w) \in \textrm{Ker}(f) \cap \textrm{Im}(f)$ tel que $x=z+w$. Par linéarité de $f$, on a :
$$ y = f(x) = f(z)+f(w) = f(w)$$
Or $w$ est dans l'image de $f$ donc il existe $x_0 \in E$ tel que $w=f(x_0)$. Ainsi,
$$ y = f(f(x_0))= f^2(x_0) \in  \textrm{Im}(f^2)$$
Finalement, $\textrm{Im}(f) \subset \textrm{Im}(f^2)$ et c'est ce qu'il fallait montrer.

\begin{Exercice}{} Soient $f,g \in \mathcal{L}(E)$ où $E$ est un $\mathbb{K}$-espace vectoriel de dimension finie. Montrer que :
    \[
    \vert \textrm{rg}(f) - \textrm{rg}(g) \vert \leq \textrm{rg}(f + g) \leq \textrm{rg}(f) + \textrm{rg}(g)
    \]
\end{Exercice}

\corr Montrons pour commencer l'inégalité de droite. Pour tout $x \in E$,
$$ (f+g)(x) = f(x) + g(x) \in \textrm{Im}(f) + \textrm{Im}(g)$$
Ainsi,
$$  \textrm{Im}(f+g) \subset  \textrm{Im}(f) + \textrm{Im}(g)$$
Les espaces sont de dimension finie donc :
$$ \textrm{dim}(\textrm{Im}(f+g)) \leq \textrm{dim}(\textrm{Im}(f) + \textrm{Im}(g))$$
D'après la formule de Grassman, on a :
$$ \textrm{dim}(\textrm{Im}(f) + \textrm{Im}(g)) = \textrm{dim}(\textrm{Im}(f)) + \textrm{dim}(\textrm{Im}(g)) - \textrm{dim}(\textrm{Im}(f) \cap \textrm{Im}(g)) \leq \textrm{dim}(\textrm{Im}(f)) + \textrm{dim}(\textrm{Im}(g))$$
Ainsi,
$$ \textrm{dim}(\textrm{Im}(f+g)) \leq \textrm{dim}(\textrm{Im}(f)) + \textrm{dim}(\textrm{Im}(g))$$
et donc :
$$\textrm{rg}(f + g) \leq \textrm{rg}(f) + \textrm{rg}(g)$$
Montrons l'inégalité de gauche. On a d'après l'inégalité de droite :
$$ \textrm{rg}(f) = \textrm{rg}(f+g-g) \leq \textrm{rg}(f+g) + \textrm{rg}(-g) = \textrm{rg}(f+g) + \textrm{rg}(g)$$
Ainsi,
$$ \textrm{rg}(f)- \textrm{rg}(g) \leq \textrm{rg}(f+g) $$
De même, on a :
$$ \textrm{rg}(g)- \textrm{rg}(f) \leq \textrm{rg}(f+g) $$
Finalement,
$$\vert \textrm{rg}(f) - \textrm{rg}(g) \vert\leq \textrm{rg}(f+g) $$


\begin{Exercice}{} Montrer que les applications suivantes sont linéaires, déterminer leur noyau et leur image (et le rang, si cela a un sens). On précisera si c'est un endomorphisme, isomorphisme ou un automorphisme et on vérifiera si l'application est bien définie.

\begin{enumerate}
\item $f : \mathbb{R}^3 \rightarrow \mathbb{R}^3$ définie par :
$$ \forall (x,y,z) \in \mathbb{R}^3, \; f((x,y,z))= (x+2y+z,y-x,2x+4y+z)$$
\item $f : \mathbb{R}^3 \rightarrow \mathbb{R}^3$ définie par :
$$ \forall (x,y,z) \in \mathbb{R}^3, \; f((x,y,z))= (x+z,x+z,x+y)$$
\item $f : \mathbb{R}_2[X] \rightarrow \mathbb{R}_2[X]$ définie par :
$$ \forall P \in \mathbb{R}_2[X], \; f(P)=P-(X+1)P'+X^2 P''$$
\item Soient la matrice $A= \begin{pmatrix}
1 & 2 \\
2 & 4 \\
\end{pmatrix}$ et $f$ l'application définie $\mathcal{M}_2(\mathbb{R})$ défini par $f(M)=AM$.
\item $\varphi : \mathcal{C}^1(I, \mathbb{R}) \rightarrow \mathcal{F}(I, \mathbb{R})$ définie par :
$$ \forall f \in \mathcal{C}(I, \mathbb{R}), \; \varphi(f)=f'$$
\end{enumerate}
\end{Exercice}

\corr 

\begin{enumerate}
\item Soient $X=(x,y,z),Y=(x',y',z) \in \mathbb{R}^3$ et $\lambda \in \mathbb{R}$. Alors :
\begin{align*}
f(\lambda X+Y) & = f((\lambda x+x',\lambda y + y', \lambda z + z')) \\
& = ((\lambda x + x')+2(\lambda y + y')+(\lambda z +z'),(\lambda y+y')-(\lambda x+x'),2(\lambda x + x')+4(\lambda y +y')+(\lambda z +z') \\
& = (\lambda (x+2y+z)+(x'+2y'+z'), \lambda (y-x) + y'-x', \lambda(2x+4y+z) + 2x'+4y'+z') \\
& = \lambda(x+2y+z,y-x,2x+4y+z) + (x'+2y'+z',y'-x',2x'+4y'+z') \\
& = \lambda f(X) + f(Y) 
\end{align*}
Soit $(x,y,z) \in \mathbb{R}^3$. Le vecteur $(x,y,z)$ appartient au noyau de $f$ si et seulement si :
\begin{align*}
& \left\lbrace \begin{array}{rl}
x+2y+z& =0 \\
y-x & = 0\\
2x+4y+z & = 0\\
\end{array}\right. \\
\Longleftrightarrow & 
\left\lbrace \begin{array}{rl}
x+2y+z& =0 \\
3y+z & = 0 \quad ( L_2 \leftarrow L_2+L_1) \\
-z & = 0 \quad ( L_3 \leftarrow L_3-2L_1)\\
\end{array}\right. \\
%\Longleftrightarrow &  \left\lbrace \begin{array}{rl}
%x+2y+z& =0 \\
%3y+z & = 0\\
% -2z & = 0 \quad ( L_3 \leftarrow 3L_3+L_2)\\
%\end{array}\right. 
\end{align*}
ce qui est équivalent à $(x,y,z)=(0,0,0)$. Ainsi, $\textrm{Ker}(f) = \lbrace (0,0,0) \rbrace$. L'application $f$ est donc un endomorphisme injectif de $\mathbb{R}^3$ qui est de dimension finie donc $f$ est un automorphisme. 
\item L'application $f$ est un endomorphisme de $\mathbb{R}^3$ (même démarche que dans la question précédente). Soit $(x,y,z) \in \mathbb{R}^3$. Le vecteur $(x,y,z)$ appartient au noyau de $f$ si et seulement si :
$$ \left\lbrace \begin{array}{rl}
x+z& =0 \\
x+y & = 0\\
\end{array}\right. 
\Longleftrightarrow z=y=-x \Longleftrightarrow (x,y,z) = x(1,-1,-1) $$
Ainsi, $\textrm{Ker}(f) = \textrm{Vect}(x_1)$ où $x_1=(1,-1,-1)$. Le vecteur $x_1$ étant non nul, il forme une base du noyau de $f$ donc le noyau est de dimension $1$. L'espace $\mathbb{R}^3$ est de dimension finie donc d'après le théorème du rang,
$$ \textrm{rg}(f) = \textrm{dim}(\mathbb{R}^3) - \textrm{dim}(\textrm{Ker}(f)) = 2$$
On sait que :
$$ \textrm{Im}(f) = \textrm{Vect}(f((1,0,0)), f((0,1,0)), f((0,0,1)))$$
Or $f((1,0,0))= (1,1,1)$, $f((0,1,0))= (0,0,1)$ et $f((0,0,1))=(1,1,0)$. Les deux premiers vecteurs sont non colinéaires donc forment une famille libre à deux éléments de l'image qui est de dimension $2$ donc :
$$ \textrm{Im}(f) = \textrm{Vect}((1,1,1),(0,1,0))$$
\item Soit $P \in \mathbb{R}_2[X]$. Il est clair que $f(P)$ est un polynôme à coefficients réels. On a :
\begin{align*}
\textrm{deg}(f(P)) & =  \textrm{deg}(P-(X+1)P'+X^2 P'')  \\
& \leq \max( \textrm{deg}(P) , \textrm{deg}((X+1)P'), \textrm{deg}(X^2P'') ) 
\end{align*}
Or le degré de $P'$ est inférieur ou égal à $n-1$ (et celui de $P''$ inférieur ou égal à $n-2$) donc le degré de $(X+1)P'$ est inférieur ou égal à $n$ et de même pour celui de $X^2P''$. Ainsi le degré de $f(P)$ est inférieur ou égal à $2$ donc $\varphi(P)$ appartient à $\mathbb{R}_2[X]$.

\medskip

\noindent Montrons la linéarité de $f$. Soient $(P,Q) \in \mathbb{R}_{2}[X]^2$ et $\lambda \in \mathbb{R}$. On a :

\begin{align*}
f(\lambda P + Q) & = (\lambda P+Q)-(X+1)(\lambda P+Q)'+X^2(\lambda P+Q)'' \\
& = \lambda P+Q - (X+1)(\lambda P' + Q') + X^2 (\lambda P''+Q'') \quad \hbox{par linéarité de la dérivation} \\
& = \lambda (P-(X+1)P'+X^2 P'') + (Q-(X+1)Q'+X^2 Q'') \\
& = \lambda f(P) + f(Q) 
\end{align*}
Ainsi, $f$ est linéaire.

\medskip

\noindent \textit{Remarque}. Si $P$ et $Q$ sont deux polynômes, on a :
$$ \textrm{deg}(P+Q) \leq \max ( \textrm{deg}(P),  \textrm{deg}(Q))$$
On a égalité \textit{si} le degré de $P$ est différent du degré de $Q$.

\medskip

\noindent Déterminons le noyau de $f$. Soit $P \in \mathbb{R}_2[X]$. Il existe $(a,b,c) \in \mathbb{R}^3$ tel que :
$$ P= aX^2+bX+c$$
et par simple calcul :
$$f(P) = aX^2-2aX+c-b$$
Ainsi, $P$ appartient au noyau de $f$ si et seulement si, par identification, $a=0$ et $c=b$ et donc si et seulement si $P =b(X+1)$. Finalement, on a $\textrm{Ker}(f)= \textrm{Vect}(X+1)$.

\medskip

\noindent Le noyau de $f$ est de dimension $1$ (car $X+1$ est différent du polynôme nul). La dimension de $\mathbb{R}_2[X]$ est trois donc d'après le théorème du rang, le rang de $f$ vaut $3-1=2$. De plus, on a :
$$ \textrm{Im}(f) = \textrm{Vect}(f(1), f(X), f(X^2)) = \textrm{Vect}(1,-1, X^2-2X) = \textrm{Vect}(1,X^2-2X)$$
car $1$ et $-1$ sont colinéaires. Ainsi, $(1,X^2-2X)$ est une famille génératrice de l'image de $f$, de cardinal $2$ qui est la dimension de cette image, c'est donc une base de l'image.
\item Il est clair que pour tout $M \in \mathcal{M}_2(\mathbb{R})$. Pour tout $(M,N) \in \mathcal{M}_2(\mathbb{R})$ et tout réel $\lambda$,
$$ f(\lambda M + N) = A(\lambda M+N) = \lambda AM + AN = \lambda f(M)+ f(N)$$

\medskip

\noindent Déterminons le noyau de $f$. Soit $M = \begin{pmatrix}
a&b \\
c & d \\
\end{pmatrix} \in \mathcal{M}_2(\mathbb{R})$. Alors :
\begin{align*}
M \in \textrm{Ker}(f) & \Longleftrightarrow  AM = 0_2 \\
& \Longleftrightarrow \begin{pmatrix}
a+2c & b+2d \\
2a+4c & 2b+4d \\
\end{pmatrix} = 0_2 \\
& \Longleftrightarrow \left\lbrace \begin{array}{cl}
a+2c & = 0 \\
b+2d & = 0 \\
\end{array}\right. \\
& \Longleftrightarrow \left\lbrace \begin{array}{cl}
a& = -2c \\
b & = -2d \\
\end{array}\right. \\
& \Longleftrightarrow  M = a \begin{pmatrix}
-2 & 0 \\
1 & 0 \\
\end{pmatrix} + d \begin{pmatrix}
0 & -2 \\
0 & 1 \\
\end{pmatrix}
\end{align*}
Ainsi,
$$ \textrm{Ker}(f) = \textrm{Vect}(M_1,M_2)$$
où
$$ M_1 = \begin{pmatrix}
-2 & 0 \\
1 & 0 \\
\end{pmatrix} \quad \hbox{ et } \quad M_2 = \begin{pmatrix}
0 & -2 \\
0 & 1 \\
\end{pmatrix}$$
Les matrices $M_1$ et $M_2$ étant non colinéaires, on en déduit que $(M_1,M_2)$ est une base de $\textrm{Ker}(f)$.

\medskip

\noindent L'application $f$ est un endomorphisme d'un espace vectoriel de dimension finie et non injectif d'après la question précédente donc $f$ n'est pas surjectif. D'après la question 1. et le théorème du rang, le rang de $f$ vaut $2$. Il suffit de déterminer une famille libre de l'image de $f$ qui contient deux éléments pour déterminer une base. On a :
$$  f \left( \begin{pmatrix}
1 & 0 \\
0 & 0
\end{pmatrix} \right) = \begin{pmatrix}
1 & 0 \\
2 & 0 \\
\end{pmatrix}$$
et 
$$  f \left( \begin{pmatrix}
0 & 1 \\
0 & 0
\end{pmatrix} \right) = \begin{pmatrix}
0 & 1 \\
0 & 2 \\
\end{pmatrix}$$
Les deux matrices $M_3=\begin{pmatrix}
1 & 0 \\
2 & 0 \\
\end{pmatrix}$ et $M_4=\begin{pmatrix}
0 & 1 \\
0 & 2 \\
\end{pmatrix}$ étant non colinéaires, on en déduit que $(M_3,M_4)$ est une base de $\textrm{Im}(f)$.
\item L'application est linéaire par linéarité de la dérivation. L'application $\varphi$ n'est pas injective car les fonctions constantes ont toutes la même image : la fonction nulle. L'application $\varphi$ n'est pas surjective car pour tout $f \in \mathcal{C}^1(I, \mathbb{R})$, $\varphi(f)=f'$ est continue sur $I$ et il existe des fonctions définies sur $I$ non continues.
\medskip

\noindent Soit $f \in \mathcal{C}^1(I, \mathbb{R})$. Si $f$ appartient au noyau de $\varphi$ alors $\varphi(f)=f'$ est la fonction nulle définie sur l'intervalle $I$ et $f$ est donc constante. Réciproquement, toute fonction constante définie sur $I$ appartient au noyau de $\varphi$. Ainsi, en notant $\tilde{1}$ la fonction constante égale à $1$, on a :
$$ \textrm{Ker}(f) = \textrm{Vect}( \tilde{1} )$$
\medskip

\noindent Soit $f \in \mathcal{C}^1(I, \mathbb{R})$. Alors $\varphi(f) = f'$ est continue sur $I$. Réciproquement si $f : I \rightarrow \mathbb{R}$ est continue sur $I$, elle admet une primitive $F : I \rightarrow \mathbb{R}$ de classe $\mathcal{C}^1$ sur $I$ et $\varphi(F)=F'=f$. Ainsi, 
$$  \textrm{Im}(\varphi) = \mathcal{C}^0(I, \mathbb{R})$$
\end{enumerate}

\begin{Exercice}{} Soit $\Delta : \mathbb{C}[X] \rightarrow \mathbb{C}[X]$ l'application définie par :
  \[
  \Delta (P ) = P( X + 1 ) - P(X )
  \]
  \begin{enumerate}
  \item
    Montrer que $\Delta$ est un endomorphisme de $\mathbb{C}[X]$ et que pour tout polynôme $P$ non constant, $\textrm{deg} ( \Delta(P)) = \textrm{deg}(P) - 1$.
  \item
    Déterminer $\textrm{Ker}(\Delta)$ et $\textrm{Im}(\Delta)$.
  \item Soient $P \in \mathbb{C}[X]$ et $n \in \N$. Montrer que :
    \[
    \Delta^{n}(P) = ( - 1)^{n} \sum_{k = 0}^{n} ( - 1)^{k} \binom{n}{k}P(X + k)
    \]
  \item En déduire que, si $\textrm{deg}(P) < n$, alors :
    \[
    \sum_{k = 0}^{n} \binom{n}{k}( - 1)^{k} P(k) = 0 
    \]
  \end{enumerate}
\end{Exercice} 

\corr 

\begin{enumerate}
\item Pour tout $P \in \mathbb{C}[X]$, $\Delta(P) \in \mathbb{C}[X]$. Soient $(P,Q) \in \mathbb{C}[X]^2$ et $\lambda \in \mathbb{C}$,
\begin{align*}
\Delta(\lambda P +Q) & = (\lambda P+Q)(X+1) - (\lambda P +Q)(X) \\
& = \lambda (P(X+1)-P(X)) + Q(X+1)-Q(X) \\
& = \lambda \Delta(P) + \Delta(Q)
\end{align*}
Ainsi, $\Delta$ est linéaire.

\medskip

\noindent Soit $P$ un polynôme non constant :
$$ P(X) = a_0 + a_1 X + \cdots + a_n X^n$$
où $(a_0, \cdots, a_n) \in \mathbb{C}^n$, $a_n \neq 0$ et $n \in \mathbb{N}$. Par linéarité de $P$, on a :
$$ \Delta(P) = a_0 \Delta(1)+ a_0 \Delta(X) + \cdots + a_n \Delta(X^n)$$
Pour tout $k \in \Interv{0}{n-1}$,
$$ \Delta(X^k) = (X+1)^k - X^k = \sum_{j=0}^{k-1} \binom{k}{j} X^j$$
donc $\textrm{deg}(\Delta(X^k))=k-1 \leq n-2$. De même, le degré de $\Delta(X^n)$ vaut $n-1$. Sachant que $a_n$ est non nul, on en déduit que le degré de $\Delta(P)$ vaut $n-1$ et ainsi,
$$ \textrm{deg}(\Delta(P)) = \textrm{deg}(P)-1$$
\item Déterminons le noyau de $\Delta$. Soit $P \in \mathbb{C}[X]$. Si $P$ est dans le noyau de $\Delta$ alors $\Delta(P)$ est le polynôme nul donc de degré $- \infty$. D'après la question précédente, $P$ ne peut pas être de degré supérieur ou égal à $1$ donc $P$ est constant. Réciproquement, si $P$ est constant, il est évident que $P$ est dans le noyau de $\Delta$. Ainsi,
$$ \textrm{Ker}(\Delta) = \textrm{Vect}(1)$$

\medskip

\noindent Soit $n \in \mathbb{N}^*$. D'après la question précédente, pour tout $k \in \Interv{1}{n+1}$, le degré de $\Delta(X^k)$ vaut $k-1$ donc la famille :
$$ \mathcal{F}_n = (\Delta(X), \Delta(X^2), \ldots, \Delta(X^{n+1}))$$
 est une famille de polynômes non nuls échelonnée en degré. C'est donc une famille libre de $\mathbb{C}_n[X]$, de cardinal $n+1$, qui est la dimension de $\mathbb{C}_n[X]$. C'est donc une base de cet espace. Ainsi,
 $$ \textrm{Vect}(\Delta(X), \Delta(X^2), \ldots, \Delta(X^{n+1})) = \mathbb{C}_n[X]$$
 Par linéarité de $\Delta$, on en déduit que tout polynôme de $\mathbb{C}_n[X]$ admet un antécédent par $\Delta$, et cela pour tout entier $n \geq 1$. Ainsi, $\Delta$ est surjective et :
 $$ \textrm{Im}(\Delta) = \mathbb{C}[X]$$
 \item Posons $f : \mathbb{C}[X] \rightarrow \mathbb{C}[X]$ définie par $f(P)=P(X+1)$. Alors $\Delta = f - \textrm{Id}$. Les applications $f$ et $\textrm{Id}$ commutent donc d'après la formule du binôme de Newton, on en déduit que pour tout $n \geq 0$,
 $$ \Delta^n = \sum_{k=0}^n \binom{n}{k} f^k (- \textrm{Id})^{n-k}  = (-1)^n \sum_{k=0}^n \binom{n}{k} f^k (-1)^k$$
 Une récurrence immédiate montre que :
 $$ \forall P \in \mathbb{C}[X], \; \Delta^k (P)= P(X+k)$$
 Ce qui donne le résultat.
 \item Soit $P \in \mathbb{C}[X]$ un polynôme de degré $k <n$. D'après la question $1$, $\Delta(P)$ a un degré inférieur ou égal à $k-1$ puis $\Delta^2(P)$ a un degré inférieur ou égal à $k-2$. De proche en proche, on obtient que $\Delta^k(P)$ a un degré inférieur ou égal à $0$ donc $\Delta^k(P)$ est constant (donc appartient au noyau de $\Delta$). Sachant que $n>k$, on en déduit que $\Delta^n(P)$ est le polynôme nul. D'après la question, on en déduit que :
$$\sum_{k = 0}^{n} ( - 1)^{k} \binom{n}{k}P(X + k) = \theta$$
 En évaluation en $0$, on obtient :
 $$ \sum_{k = 0}^{n} ( - 1)^{k} \binom{n}{k}P(k)$$
\end{enumerate}

\begin{Exercice}{} 
\begin{enumerate}
\item Montrer que $H$ défini par :
$$ H = \lbrace (x_1, \ldots, x_n)\in \mathbb{R}^n \; \vert \;    x_1 + \cdots + x_n = 0 \rbrace$$
est un sous-espace vectoriel de $\mathbb{R}^n$ et donner sa dimension.
\item Déterminer l'expression de la symétrie par rapport à $H$ parallèlement à $G$ définie par :
$$ G = \textrm{Vect}((1,1, \ldots, 1))$$
\end{enumerate}
\end{Exercice}

\corr

\begin{enumerate}
\item $H$ est le noyau de la forme linéaire $\varphi : \mathbb{R}^n \rightarrow \mathbb{R}$ par :
$$ \varphi((x_1, \ldots, x_n))=  x_1 + \cdots + x_n$$
Cette forme linéaire est non nulle ($\varphi((1,1, \ldots, 1)) = n \neq 0$) donc c'est un hyperplan de $\mathbb{R}^n$ donc un espace vectoriel de dimension $n-1$.
\item Raisonnons par analyse-synthèse pour montrer que $\mathbb{R}^n = F \oplus G$.

\medskip

\noindent \textit{Analyse.} Supposons que $\mathbb{R}^n = F \oplus G$. Soit $(x_1, \ldots, x_n) \in \mathbb{R}^n$. Il existe un vecteur $(a_1, \ldots, a_n)$ de $F$ et un vecteur de $G$, de la forme $\alpha (1, \ldots, 1)$ avec $\alpha \in \mathbb{R}$, tel que :
$$ (x_1, \ldots, x_n) = (a_1, \ldots, a_n) + \alpha (1, \ldots, 1)$$
On sait que $\dis \sum_{i=1}^n a_i=0$ donc :
$$ \sum_{i=1}^n x_i = \sum_{i=1}^n \alpha = n \alpha$$
et ainsi :
$$ \alpha = \dfrac{1}{n} \sum_{i=1}^n x_i $$
On a donc pour tout $i \in \Interv{1}{n}$,
$$ a_i = x_i - \alpha = x_i - \dfrac{1}{n} \sum_{i=1}^n x_i$$

\medskip

\noindent \textit{Synthèse.} Soit $(x_1, \ldots , x_n) \in \mathbb{R}^n$. Posons :
$$ g = \alpha (1, \ldots, 1) \hbox{ où } \alpha =  \dfrac{1}{n} \sum_{i=1}^n x_i$$
et 
$$ f = (x_1, \ldots, x_n) - g$$
Ainsi, $f+g= (x_1, \ldots, x_n)$, $g$ appartient à $G$ et $f \in F$ car :
$$ f = (x_1-\alpha, \ldots, x_n - \alpha)$$
et
$$ \sum_{i=1}^n (x_i - \alpha)  = \left(\sum_{i=1}^n x_i \right) - n \alpha = \sum_{i=1}^n x_i- \sum_{i=1}^n x_i = 0$$

\medskip

\noindent On a donc montré que tout vecteur de $\mathbb{R}^n$ s'écrit comme la somme d'un élément de $F$ et d'un élément de $G$. Cette décomposition est unique d'après l'analyse. Ainsi, $F$ et $G$ sont supplémentaires dans $\mathbb{R}^n$.

\medskip

\noindent Notons $s$ la symétrie par rapport à $F$ parallèlement à $G$. D'après le raisonnement précédent (en gardant les notations), on a :
\begin{align*}
s((x_1, \ldots, x_n)) & = f-g \\
& = (x_1-\alpha, \ldots, x_n - \alpha) - (\alpha, \ldots, \alpha) \\
& = (x_1 - 2\alpha, \ldots, x_n -2 \alpha) \\
& = \left( x_1 - 2 \dfrac{x_1+ \cdots x_n}{n}, \ldots,  x_n - 2 \dfrac{x_1+ \cdots x_n}{n}\right) 
\end{align*}
\end{enumerate}

\begin{Exercice}{} Donner l'expression de la projection de $\mathcal{M}_n(\mathbb{R})$ sur $\mathcal{S}_n(\mathbb{R})$ parallèlement à $\mathcal{A}_n(\mathbb{R})$ et celle de la symétrie par rapport à $\mathcal{S}_n(\mathbb{R})$ parallèlement à $\mathcal{A}_n(\mathbb{R})$.
\end{Exercice}

\corr Voir le TD précédent pour la preuve. En notant $p$ cette projection et $s$ la symétrie, on a pour tout $M \in \mathcal{M}_n(\mathbb{R})$, 
$$ p(M) = \dfrac{M+ ~^t M}{2}$$
et 
$$ s(M) =  \dfrac{M+ ~^t M}{2} -  \dfrac{M- ~^t M}{2} =~^t M$$



\begin{Exercice}{} Donner l'expression de la projection de $\mathcal{F}(\mathbb{R}, \mathbb{R})$ sur le sous-espace vectoriel $P$ des fonctions paires parallèlement au sous-espace vectoriel $I$ des fonctions impaires.
\end{Exercice}

\corr Voir le TD précédent pour la preuve. En notant $p$ cette projection, on a pour toute fonction $f \in \mathcal{F}(\mathbb{R}, \mathbb{R})$,
$$ p(f)(x) = \dfrac{f(x)+f(-x)}{2}$$




%\noindent Dans la suite, $\mathbb{K}= \mathbb{R}$ ou $\mathbb{C}$.
%
%\medskip
%
%\begin{center}
%{\large \textit{\underline{Noyaux, images}}}
%\end{center}
%
%\bigskip
%%
%%\exo Soit $f$ l'application de $\mathbb{R}^4$ dans $\mathbb{R}^4$ définie par 
%%\[ f(x,y,z,t) = (x+2y+t,2x+z,-5x+6y-4z+3t,4x+4y+z+2t) \]
%%
%%\begin{enumerate}
%%\item Montrer que $f$ est une application linéaire.
%%\item Déterminer le noyau de $f$.
%%\item Que vaut le rang de $f$?
%%\end{enumerate}
%%
%%\medskip
%
%
%\exo Soit $n \in \mathbb{N}^*$. On pose pour tout $P \in \mathbb{R}_n[X]$, $\Delta(P)= P-P'$.
%
%\begin{enumerate}
%\item Montrer que $\Delta$ induit un endomorphisme de $\mathbb{R}_n[X]$.
%\item Déterminer le noyau et l'image de $\Delta$.
%\end{enumerate}
%
%\medskip
%

%    
%\medskip
%

%\medskip
%
%\exo Soit $f$ un endomorphisme d'un $\mathbb{K}$-espace vectoriel $E$ vérifiant $f^3 = \textrm{Id}_E$. Montrer que :
%    \[
%    \textrm{Ker}(f -  \textrm{Id}_E) \oplus  \textrm{Im}(f - \textrm{Id}_{E}) = E
%    \]
%

%
%
%\exo Soient $A = \begin{pmatrix}
%1 & 1 \\
%0 & 1 \\
%\end{pmatrix}$ et $\varphi : \mathcal{M}_2(\mathbb{R}) \rightarrow \mathcal{M}_2(\mathbb{R})$ définie par $\varphi(M)= AM-MA$.
%
%\begin{enumerate}
%\item Montrer que $\varphi$ est un endomorphisme de $\mathcal{M}_2(\mathbb{R})$.
%\item Donner une base $\textrm{Ker}{(\varphi)}$ et une base de $\textrm{Im}{(\varphi)}$.
%\end{enumerate}
%
%
%
%\newpage
%
%
%\begin{center}
%{\large \textit{\underline{Projections, symétries}}}
%\end{center}
%
%\medskip
%
%\exo Soient $E$ un $\mathbb{C}$-espace vectoriel de dimension finie et $u \in \mathcal{L}(E)$. On suppose qu'il existe un projecteur $p$ de $E$ tel que $u = p \circ u - u \circ p$.
%\begin{enumerate}
%\item Montrer que $u(\textrm{Ker} (p)) \subset \textrm{Im}(p)$ et $\textrm{Im}(p) \subset \textrm{Ker}(u)$.
%\item En déduire $u^2 = \theta$ (endomorphisme nul).
%\item La réciproque est-elle vraie ?
%    \end{enumerate}
%\bigskip
%

%\exo Soient $n \in \mathbb{N}^*$ et $(e_1, \ldots, e_n)$ une base d'un $\mathbb{K}$-espace vectoriel $E$. Posons pour tout $i \in \Interv{1}{n}$,
%$$ F_i = \lbrace u \in \mathcal{L}(E), \, \textrm{Im}(u) \subset \textrm{Vect}(e_i) \rbrace$$
%Montrer que $\mathcal{L}(E) = F_1 \oplus F_2 \oplus \cdots \oplus F_n$.
%
%\medskip
%
%\exo Trouver toutes les formes linéaires $\Phi$ de $\mathcal{M}_n(\mathbb{R})$ vérifiant :
%$$ \forall (A,B) \in \mathcal{M}_n(\mathbb{R})^2, \, \Phi(AB)= \Phi(BA)$$
%
%\medskip
%
%\exo Soit $f \in \mathcal{L}(\mathbb{R}^6)$ tel que $\textrm{rg}(f^2) = 3$. Quels sont les rangs possibles pour $f$?



\end{document}