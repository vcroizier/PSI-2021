\documentclass[french,11pt,twoside]{VcCours}
\newcommand{\dt}{\text{d}t}
\newcommand{\dx}{\text{d}x}

\renewcommand{\trou}[1]{{\color{white}#1}}
%\renewcommand{\trou}[1]{{\color{blue}#1}}


\begin{document}

\Titre{PSI}{Promotion 2021--2022}{Mathématiques}{Chapitre 18 : Endomorphismes d'un espace euclidien}

\tableofcontents
\separationTitre

Dans tout le chapitre, $E$ désignera un espace euclidien de dimension $n \geq 1$, muni d'un produit scalaire $< \cdot \, , \cdot>$ et dont la norme euclidienne sera notée $\Vert \cdot \Vert$.

\medskip

\section{Isométries vectorielles}
\subsection{Définition et caractérisation}
\begin{Definition}{} Soit $f \in \mathcal{L}(E)$. On dit que $f$ est une \emph{isométrie vectorielle} si elle conserve la norme, c'est-à-dire si :
$$ \forall x \in E, \; \Vert f(x) \Vert = \Vert x \Vert$$
\end{Definition}

\begin{Exemple}{} Soit $F$ un sous-espace vectoriel de $E$. Montrer que la symétrie orthogonale sur $F$ est une isométrie vectorielle.

\vspace{6cm}
\end{Exemple}

\begin{Remarque}{} Une projection orthogonale sur un sous-espace $F$ de $E$, différent de $E$, n'est pas une isométrie vectorielle. Si $x \in F^{\perp}$ avec $x$ non nul (la dimension de $F^{\perp}$ vaut au moins $1$ d'après l'hypothèse et le fait que $E$ soit de dimension finie) alors son projeté orthogonal sur $F$ est le vecteur nul qui a donc une norme nulle alors que $x$ n'a pas une norme nulle.
\end{Remarque}

\begin{ApplicationDirecte}{} Que peut-on dire des valeurs propres d'une isométrie vectorielle ?
\end{ApplicationDirecte}

\begin{Proposition}{} Une isométrie vectorielle de $E$ est un automorphisme de $E$.
\end{Proposition}

\begin{Demonstration}{}

\vspace{2.5cm}
\end{Demonstration}

\begin{Proposition}{Caractérisation par le produit scalaire}
Soit $f \in \mathcal{L}(E)$. Les assertions suivantes sont équivalentes :
\begin{enumerate}
\item $f$ est une isométrie vectorielle.
\item $f$ conserve le produit scalaire, c'est-à-dire :
$$ \forall (x,y) \in E^2, \; <f(x),f(y)>=<x,y> $$
\end{enumerate}
\end{Proposition}

\begin{Remarque}{} Une isométrie vectorielle est aussi appelée un \emph{automorphisme orthogonal} (cohérent avec les deux dernières propositions).
\end{Remarque}

\begin{Demonstration}{}
\vspace{7cm}
\end{Demonstration}

\begin{Proposition}{Caractérisation par l'image d'une B.O.N}
Soient $f \in \mathcal{L}(E)$ et $\mathcal{B}$ une base orthonormée de $E$. Les assertions suivantes sont équivalentes :
\begin{enumerate}
\item $f$ est une isométrie vectorielle.
\item L'image de $\mathcal{B}$ par $f$ est une base orthonormée de $E$.
\end{enumerate}
\end{Proposition}

\begin{Demonstration}{}
\vspace{7cm}
\end{Demonstration}

\subsection{Groupe orthogonal}

\begin{Definition}{} L'ensemble des isométries vectorielles de $E$ est appelé \emph{groupe orthogonal} de $E$ et est noté $\mathcal{O}(E)$. 
\end{Definition}

L'appellation groupe orthogonal est justifié par le fait que $\mathcal{O}(E)$, muni de la composition, est un sous-groupe de l'ensemble des bijections de $E$ :

\begin{Proposition}{} 
\begin{itemize}
\item $\textrm{Id}_E \in \mathcal{O}(E)$.
\item $\forall (f,g) \in \mathcal{O}(E)^2, \; f \circ g \in \mathcal{O}(E)$.
\item $\forall f \in \mathcal{O}(E), \; f^{-1} \in \mathcal{O}(E)$.
\end{itemize}
\end{Proposition}

\begin{Demonstration}{}
\vspace{5cm}
\end{Demonstration}

\newpage

$\phantom{test}$

\vspace{2.5cm}

\subsection{Isométrie et stabilité}

\begin{Proposition}{} Soient $f \in \mathcal{O}(E)$ et $F$ un sous-espace vectoriel de $E$ stable par $f$. Alors $F^{\perp}$ est stable par $f$.
\end{Proposition}

\begin{Demonstration}{}

\vspace{5cm}
\end{Demonstration}


\section{Matrices orthogonales}

Rappelons que le produit scalaire usuel sur $\mathcal{M}_{n,1}(\mathbb{R})$ est défini par :
$$ \forall (X,Y) \in \mathcal{M}_{n,1}(\mathbb{R})^2, \; <X,Y> = ~^tX Y$$
\subsection{Définition et caractérisations}

\begin{Definition}{} Soit $M \in \mathcal{M}_n(\mathbb{R})$. On dit que $M$ est une \emph{matrice orthogonale} si l'endomorphisme $u_M$ de $\mathcal{M}_{n,1}(\mathbb{R})$, canoniquement associé à $M$, est une isométrie vectorielle pour la norme associée au produit scalaire usuel sur $\mathcal{M}_{n,1}(\mathbb{R})$.
\end{Definition}

\begin{Proposition}{} Soit $M \in \mathcal{M}_n(\mathbb{R})$. Les assertions suivantes sont équivalentes :
\begin{enumerate}
\item $M$ est une matrice orthogonale.
\item $^tM M=I_n$.
\item $M ^tM=I_n$.
\item $M$ est inversible et son inverse est $^tM$.
\item Les colonnes de $M$ forment une famille orthonormée de $\mathcal{M}_{n,1}(\mathbb{R})$ muni du produit scalaire usuel (dans ce cas, elles forment une base orthonormée de $\mathcal{M}_{n,1}(\mathbb{R}))$.
\item Les lignes de $M$ forment une famille orthonormée de $\mathbb{R}^n$ muni du produit scalaire usuel (dans ce cas, elles forment une base orthonormée de $\mathbb{R}^n$.
\end{enumerate}
\end{Proposition}

\begin{Demonstration}{}

\vspace{7cm}
\end{Demonstration}

\newpage

$\phantom{test}$

\vspace{5cm}

\begin{ApplicationDirecte}{} Soient $(a,b,c) \in \R^{3}$, $\sigma = ab + bc + ca$, $S = a + b + c$ et $M$ la matrice définie par :
  \[
  M =
  \begin{pmatrix}
    a & b & c \\
    c & a & b \\
    b & c & a
  \end{pmatrix}
  \]
Montrer que $M$ est orthogonale si et seulement si  $\sigma = 0$ et $S \in \lbrace -1,1 \rbrace\cdot$
\end{ApplicationDirecte}
 
\subsection{Groupe orthogonal d'ordre \texorpdfstring{$n$}{n}}

\begin{Definition}{} L'ensemble des matrices orthogonales est appelé \emph{groupe orthogonal d'ordre} $n$. On le note $\mathcal{O}(n)$ ou $\mathcal{O}_n(\mathbb{R})$. On a ainsi :
$$ \mathcal{O}(n) = \lbrace M \in \mathcal{M}_n(\mathbb{R}) \, \vert \, ^tM M=I_n \rbrace$$
\end{Definition}

L'appellation groupe orthogonal est justifié par le fait que $\mathcal{O}(n)$, muni du produit matriciel, est un sous-groupe de $\textrm{GL}_n(\mathbb{R})$ :

\begin{Proposition}{} 
\begin{itemize}
\item $I_n \in \mathcal{O}(n)$.
\item $\forall (M,N) \in \mathcal{O}(n)^2, \; MN \in \mathcal{O}(n)$.
\item $\forall M \in \mathcal{O}(n), \; M^{-1} \in \mathcal{O}(n)$.
\end{itemize}
\end{Proposition}

\begin{Demonstration}{}
\vspace{5cm}
\end{Demonstration}

\begin{Proposition}{Lien entre isométries vectorielles et matrices orthogonales}
Soient $f \in \mathcal{L}(E)$ et $\mathcal{B}$ une base orthonormée de $E$.  Les assertions suivantes sont équivalentes :
\begin{enumerate}
\item $f$ est un isométrie vectorielle.
\item La matrice $M$ de $f$ dans la base $\mathcal{B}$ est orthogonale.
\end{enumerate}
\end{Proposition}

\begin{Demonstration}{}
\vspace{5cm}
\end{Demonstration}

\newpage

$\phantom{test}$

\vspace{5cm}

\begin{Exemple}{} Soit $f$ l'endomorphisme de $\mathbb{R}^3$ (muni du produit scalaire usuel) défini par :
$$ \forall (x,y,z) \in \mathbb{R}^3, \; f((x,y,z)) = \dfrac{1}{\sqrt{2}} (-x+y , \sqrt{2}z, x+y)$$
Déterminer la matrice de $f$ dans la base canonique de $\mathbb{R}^3$. Qu'en déduit-on ?


\vspace{5cm}

\end{Exemple}

\begin{Proposition}{} Les matrices orthogonales sont les matrices de changement de bases orthonormées. 

Autrement dit : si $\mathcal{B}$ est une base orthonormée de $E$ (de dimension $n$) et $\mathcal{F}$ une famille de $n$ vecteurs de $E$ alors la matrice de la famille $\mathcal{F}$ dans $\mathcal{B}$ est une matrice orthogonale si et seulement si $\mathcal{F}$ est une base orthonormée.
\end{Proposition}

\begin{Demonstration}{}
\vspace{3cm}
\end{Demonstration}

\begin{Remarque}{} Ainsi, si $\mathcal{B}$ et $\mathcal{B}'$ sont deux bases orthonormées de $E$ alors $P_{\mathcal{B}, \mathcal{B}'}$ est orthogonale donc :
$$P_{\mathcal{B}', \mathcal{B}} = (P_{\mathcal{B}, \mathcal{B}'})^{-1} = \, ^t(P_{\mathcal{B}, \mathcal{B}'})$$
La formule de changement de base pour un endomorphisme $u$ de $E$ s'écrit alors :
$$ \textrm{Mat}_{\mathcal{B'}}(u) = \,  ^tP \textrm{Mat}_{\mathcal{B}}(u) P$$
où $P$ est la matrice de passage de $\mathcal{B}$ vers $\mathcal{B}'$.
\end{Remarque}

\begin{Proposition}{} 
\begin{itemize}
\item Une matrice orthogonale a un déterminant égal à $1$ ou $-1$.
\item Une isométrie vectorielle a un déterminant égal à $1$ ou $-1$.
\end{itemize}
\end{Proposition}

\begin{Demonstration}{}
\vspace{4cm}
\end{Demonstration}

\begin{ApplicationDirecte}{} Déterminer une matrice ayant pour déterminant $1$ et qui ne soit pas orthogonale.
\end{ApplicationDirecte}

\begin{Definition}{} L'ensemble des matrices orthogonales de $\mathcal{M}_n(\mathbb{R})$ de déterminant égal à $1$, est appelé \emph{groupe spécial orthogonal d'ordre $n$}. On le note $\mathcal{SO}(n)$ ou $\mathcal{SO}_n(\mathbb{R})$.
\end{Definition}

\begin{Proposition}{} $\mathcal{SO}(n)$ est stable par produit et par passage à l'inverse.
\end{Proposition}

\begin{Demonstration}{}

\vspace{3cm}
\end{Demonstration}

\begin{Definition}{} Si $E$ est de dimension $2$ ou $3$, les éléments de $\mathcal{SO}(E)$ sont appelés \emph{rotations} de $E$.
\end{Definition}


\section{Endomorphismes symétriques}
\subsection{Généralités}
\begin{Definition}{}
Soit $f \in \mathcal{L}(E)$. On dit que $f$ est un \emph{endomorphisme symétrique} si : 
$$ \forall (x,y) \in E^2, \; <f(x),y>=<x,f(y)>$$
\end{Definition}

\begin{Exemple}{} Montrons qu'une projection orthogonale sur un sous-espace vectoriel $F$ de $E$ est un endomorphisme symétrique.

\vspace{5cm}
\end{Exemple}

\begin{ApplicationDirecte}{} Considérons $E=\mathcal{M}_n(\mathbb{R})$ muni du produit scalaire usuel et $f$ l'endomorphisme de $E$ défini par $f(M) = \, ^t M$. Montrer que $f$ est un endomorphisme symétrique.
\end{ApplicationDirecte}

\begin{Proposition}{Lien entre endomorphisme symétrique et matrice symétrique}
Soient $f \in \mathcal{L}(E)$ et $\mathcal{B}$ une base orthonormée de $E$. Les assertions suivantes sont équivalentes :
\begin{enumerate}
\item $f$ est un endomorphisme symétrique.
\item La matrice $M$ de $f$ dans la base $\mathcal{B}$ est symétrique.
\end{enumerate}
\end{Proposition}

\begin{Demonstration}{}
\vspace{7cm}
\end{Demonstration}

\subsection{Théorème spectral}
\begin{Proposition}{} Soient $f \in \mathcal{L}(E)$ un endomorphisme symétrique et $\lambda$, $\mu$, deux valeurs propres distinctes de $f$. Alors $E_{\lambda}(f) \perp E_{\mu}(f)$.
\end{Proposition}

\begin{Demonstration}{}
\vspace{5cm}
\end{Demonstration}

\begin{Theoreme}{Théorème spectral}
Soit $f \in \mathcal{L}(E)$ un endomorphisme symétrique. Alors $f$ est diagonalisable dans une base orthonormée.
\end{Theoreme}

\begin{Remarques}{}
\begin{itemize} 
\item Il existe donc une base orthonormée de vecteurs propres de $f$.
\item Un endomorphisme symétrique a donc un polynôme caractéristique scindé et toutes ses valeurs propres sont réelles.
\end{itemize}
\end{Remarques}

\begin{Theoreme}{Théorème spectral matriciel}
Soit $M$ une matrice symétrique \emph{réelle}. Alors :
\begin{itemize}
\item Il existe une matrice diagonale $D \in \mathcal{M}_n(\mathbb{R})$ dont les coefficients diagonaux sont les valeurs propres de $M$.
\item Il existe une matrice orthogonale $P \in \mathcal{O}(n)$ dont les colonnes constituent une base orthonormée de $\mathcal{M}_{n,1}(\mathbb{R})$ (pour le produit scalaire usuel) de vecteurs propres de $M$.
\item On a l'égalité : $M = P D \, ^tP$.
\end{itemize}
\end{Theoreme}

\begin{ApplicationDirecte}{} La matrice $\begin{pmatrix}
1 &i \\
i & -1 \\
\end{pmatrix}$ est-elle diagonalisable ? Moralité?
\end{ApplicationDirecte}

\begin{Exemple}{} Justifier que
  \[
  A =
  \begin{pmatrix}
    1 &  - 2 &  - 2 \\
    - 2 & 1 &  - 2 \\
    - 2 &  - 2 & 1
  \end{pmatrix}
  \]
  est diagonalisable et trouver $P$ telle que $^tPAP$ soit diagonale.
  
\vspace{13cm}
\end{Exemple}

\begin{ApplicationDirecte}{} Justifier que
  \[
  A =
  \begin{pmatrix}
    1 &  1 &  1 \\
  1 &  1 &  1 \\
    1 &  1 &  1 \\
  \end{pmatrix}
  \]
est diagonalisable et trouver $P$ telle que $^tPAP$ soit diagonale.
\end{ApplicationDirecte}



\section{Espaces euclidiens orientés de dimension 2 ou 3}
\subsection{Orientation}
Considérons deux bases orthonormées, $\mathcal{B}$ et $\mathcal{B}'$, de $E$ et $P= P_{\mathcal{B}, \mathcal{B}'}$. Alors $P$ est une matrice de passage entre deux bases orthonormées et est donc une matrice orthogonale. Ainsi le déterminant de $P$ vaut $1$ ou $-1$. Ainsi le déterminant de $P^{-1}= P_{\mathcal{B}', \mathcal{B}}$ est égal au déterminant de $P$ et donc :
$$ \textrm{det}_{\mathcal{B}}(\mathcal{B}') =  \textrm{det}_{\mathcal{B}'}(\mathcal{B})$$
et $\textrm{det}_{\mathcal{B}}(\mathcal{B}')  \in \lbrace -1,1 \rbrace \cdot$

\begin{Definition}{}
\begin{itemize}
\item On dit que $\mathcal{B}$ et $\mathcal{B}'$ ont la même \emph{orientation} si $\textrm{det}_{\mathcal{B}}(\mathcal{B}')=1$.
\item \emph{Orienter} l'espace $E$ c'est fixer une base orthonormée de référence et choisir l'ensemble des bases orthonormées qui ont la même orientation. Ces bases sont alors dites \emph{bases orthonormées directes}. Les autres bases sont dites \emph{bases orthonormées indirectes}.
\end{itemize}
\end{Definition}

\begin{Remarques}{}
\begin{itemize}
\item Une matrice de passage entre deux bases orthonormées directes est une matrice orthogonale de déterminant égal à $1$ donc appartient à $\mathcal{SO}(n)$.
\item L'échange de deux vecteurs d'une base orthonormée change son orientation (directe ou indirecte).
\item La multiplication par un nombre négatif d'un des vecteurs d'une base orthonormée change son orientation.
\end{itemize}
\end{Remarques}

\subsection{Orientation d'un plan ou d'une droite en dimension 3}
Soit $E$ un espace euclidien orienté de dimension $3$.
\begin{itemize}
\item On oriente une droite vectorielle $D$ de $E$ en choisissant un vecteur directeur de $D$.
\item On oriente un plan vectoriel $P$ de $E$ en choisissant un vecteur normal $n$ à $P$. Dans ce cas, une base $(u,v)$ de $P$ est dite directe si $(u,v,n)$ est une base directe de $E$. Sinon, elle est dite indirecte.
\end{itemize}

\subsection{Produit mixte}

\begin{TheoremeDefinition}{} Soient $\mathcal{B}$ et $\mathcal{B}'$ deux bases orthonormées directes d'un espace euclidien orienté $E$ de dimension $n=2$ ou $n=3$. Alors pour toute famille $(x_1, \ldots, x_n)$ de vecteurs de $E$, on a :
$$ \textrm{det}_{\mathcal{B}}(x_1, \ldots, x_n) =  \textrm{det}_{\mathcal{B}'}(x_1, \ldots, x_n) $$
Le déterminant de la famille $(x_1, \ldots, x_n)$ ne dépend donc pas de la base orthonormée directe choisie pour le calculer. On l'appelle le \emph{produit mixte} de $(x_1, \ldots, x_n)$ et on le note $[x_1, \ldots, x_n]$.
\end{TheoremeDefinition}{}

\begin{Demonstration}{}

\vspace{5cm}
\end{Demonstration}

\begin{Remarques}{}
\begin{itemize}
\item Si $u$ et $v$ sont deux vecteurs de $\mathbb{R}^2$, $\vert [u,v]\vert$ est l'aire du parallélogramme porté par les vecteurs $u$ et $v$.
\item Si $u$, $v$ et $w$ sont trois vecteurs de $\mathbb{R}^3$, $\vert [u,v,w] \vert$ est le volume du parallélépipède rectangle porté par les vecteurs $u$, $v$ et $w$.
\end{itemize}
\end{Remarques}

\begin{Proposition}{} Soient $E$ un espace euclidien de dimension $2$ et $(u,v) \in E^2$. Alors :
\begin{itemize}
\item Échanger deux vecteurs dans un produit mixte change le signe de celui-ci.
\item Le produit mixte $[u,v]$ est nul si et seulement si $(u,v)$ est liée.
\item La famille $(u,v)$ est une base orthonormée directe si et seulement si $[u,v]=1$.
\end{itemize}
\end{Proposition}

\begin{ApplicationDirecte}{} On a des résultats analogues si $E$ est de dimension $3$ : les écrire.
\end{ApplicationDirecte}

\subsection{Produit vectoriel}

\begin{TheoremeDefinition}{} Soit $E$ un espace euclidien orienté de dimension $3$. Pour tout $(u,v) \in E^2$, il existe un unique vecteur de $E$, appelé \emph{produit vectoriel} de $u$ et $v$ et noté $u \wedge v$, tel que :
$$ \forall x \in E, \; [u,v,x]=<u \wedge v, x>$$
\end{TheoremeDefinition}{}

\begin{Demonstration}{}
\vspace{5cm}
\end{Demonstration}

\begin{Proposition}{} Soient $E$ un espace euclidien orienté de dimension $3$ et $\mathcal{B}=(e_1,e_2,e_3)$ une base orthonormée directe de $E$. Soit $(u,v) \in E^2$ tel que :
$$ u= u_1 e_2 + u_2e_2 + u_3e_3 \hbox{ et } v= v_1 e_2 + v_2e_2 + v_3e_3$$
où $(u_1,u_2,u_3)$ et $(v_1,v_2,v_3)$ appartiennent à $\mathbb{R}^3$. Alors :
$$ u \wedge v = (u_2 v_3-u_3v_2) e_1 + (u_3v_1-u_1 v_3) e_2 + (u_1v_2-u_2v_1) e_3 $$
\end{Proposition}

\begin{Remarque}{} En particulier dans $\mathcal{M}_3(\mathbb{R})$ orienté par la base canonique :
$$ \begin{pmatrix}
u_1 \\
u_2 \\
u_3 \\
\end{pmatrix} \wedge  \begin{pmatrix}
v_1 \\
v_2 \\
v_3 \\
\end{pmatrix} = \begin{pmatrix}
u_2 v_3-u_3v_2 \\
u_3v_1-u_1 v_3 \\
u_1v_2-u_2v_1\\
\end{pmatrix}$$
\end{Remarque}

\begin{Demonstration}{}

\vspace{7cm}
\end{Demonstration}

\begin{Proposition}{}
Soient $E$ un espace euclidien orienté de dimension $3$ et $(u,v) \in E^2$. Alors :
\begin{enumerate}
\item $u \wedge v = - v \wedge u$.
\item La famille $(u,v)$ est libre si et seulement si $u \wedge v \neq 0_E$.
\item Le vecteur $u \wedge v$ est orthogonal à $u$ et $v$.
\item Si $u$ et $v$ sont orthogonaux alors $\Vert u \wedge v \Vert = \Vert u \Vert \times \Vert v \Vert$.
\item Si $(e_1,e_2,e_3)$ est base orthonormée directe de $E$ alors :
$$ e_1 \wedge e_2 = e_3, \; e_2 \wedge e_3 = e_1 , \; e_3 \wedge e_1 = e_2 $$
\item Pour tout $z \in E$,
$$ u \wedge (v \wedge z) =<u,z>v-<u,v>z$$
\item Les applications $x \mapsto <u,x>$ et $x \mapsto <x,v>$ sont des endomorphismes de $E$.
\end{enumerate}
\end{Proposition}

\begin{Remarque}{} En particulier si $u$ et $v$ forment une famille libre, $u \wedge v$ est un vecteur normal au plan $\textrm{Vect}(u,v)$. Si de plus $(u,v)$ est orthonormée alors $(u,v,u \wedge v)$ est une base orthonormée directe de $E$.
\end{Remarque}

\begin{Exemple}{} Considérons $\mathbb{R}^3$ muni du produit scalaire usuel. Posons :
$$ F = \Vect((1,2,1),(0,1,-1))$$
Donnons une équation de $F$ et déterminons pour tout $\omega \in \mathbb{R}^3$, la distance de $\omega$ à $F$.

\vspace{6cm}
\end{Exemple}

\section{Classification des isométries vectorielles en dimension \texorpdfstring{$2$ et $3$}{2 et 3}}
\subsection{Classification des isométries vectorielles en dimension \texorpdfstring{$2$}{2}}

\begin{Theoreme}{Détermination de $\mathcal{O}_2(\mathbb{R})$ et $\mathcal{SO}_2(\mathbb{R})$}
On a :
$$ O_2(\mathbb{R}) = \left\lbrace \begin{pmatrix}
\cos(\theta) & - \sin(\theta) \\
\sin(\theta) & \cos(\theta) \\
\end{pmatrix}, \, \theta \in \mathbb{R} \right\rbrace \cup \left\lbrace \begin{pmatrix}
\cos(\theta) & \sin(\theta) \\
\sin(\theta) & -\cos(\theta) \\
\end{pmatrix}, \, \theta \in \mathbb{R} \right\rbrace$$
L'union est disjointe : le premier ensemble est exactement $\mathcal{SO}_2(\mathbb{R})$ et le deuxième est l'ensemble des éléments de $\mathcal{O}_2(\mathbb{R})$ de déterminant égal à $-1$.
\end{Theoreme}

\begin{Demonstration}{}
\vspace{10cm}
\end{Demonstration}

\newpage

\begin{Notation}{} La matrice définie pour $\theta \in \mathbb{R}$ par :
$$ R(\theta) =\begin{pmatrix}
\cos(\theta) & - \sin(\theta) \\
\sin(\theta) & \cos(\theta) \\
\end{pmatrix}$$
est appelée \emph{matrice de rotation} d'angle $\theta$
\end{Notation}

\begin{ApplicationDirecte}{} Montrer que pour tout $(\theta, \theta') \in \mathbb{R}^2$, $R(\theta) R(\theta') = R(\theta + \theta')$.
\end{ApplicationDirecte}

\begin{Proposition}{} $\mathcal{SO}_2(\mathbb{R})$ est commutatif (pour le produit matriciel) : 
$$ \forall (M,N) \in \mathcal{SO}_2(\mathbb{R})^2, \,  MN=NM$$
\end{Proposition}

\begin{Demonstration}{}
\vspace{3cm}
\end{Demonstration}

\begin{Remarque}{} Considérons $M(x,y)$ et $M'(x',y')$ deux points de $\mathbb{R}^2$ d'affixes $z$ et $z'$. Alors $z'$ est l'image de $z$ par la rotation d'angle $\theta \in \mathbb{R}$ si et seulement si :
$$z'= e^{i \theta } z = (\cos(\theta) + i \sin(\theta))(x+iy) = (\cos(\theta) x- \sin(\theta)y) + (\sin(\theta)x+ \cos(\theta)y)i$$
ce qui se réécrit par identification :
$$ \begin{pmatrix}
x'\\
y' \\
\end{pmatrix} = \begin{pmatrix}
\cos(\theta) & - \sin(\theta) \\
\sin(\theta) & \cos(\theta) \\
\end{pmatrix} \begin{pmatrix}
x \\
y
\end{pmatrix} = R(\theta) \begin{pmatrix}
x \\
y
\end{pmatrix}$$
\end{Remarque}

\begin{Theoreme}{Classification des isométries vectorielles en dimension $2$}
Soient $E$ un espace euclidien orienté de dimension $2$ et $f \in \mathcal{O}(E)$.
\begin{enumerate}
\item Si $\textrm{det}(f)=1$ (si $f$ est une rotation) alors il existe $\theta \in \mathbb{R}$ tel que la matrice de $f$ dans toute base orthonormée directe de $E$ soit $R(\theta)$ ($\theta$ unique modulo $2 \pi$). On dit que $\theta$ est \emph{l'angle de la rotation} $f$. On a pour tout vecteur unitaire $x_0 \in E$ :
$$ \cos(\theta) = \dfrac{1}{2} \textrm{Tr}(f)=<x_0,f(x_0)> \hbox{ et } \sin(\theta) = [x_0, f(x_0) ]$$
\item Si $\textrm{det}(f) = -1$ alors $f$ est la symétrie orthogonale par rapport à $\textrm{Ker}(f-\textrm{Id})$ par rapport à $\textrm{Ker}(f-\textrm{Id})^{\perp}$. Dans une base adapté à la décomposition $E= \textrm{Ker}(f-\textrm{Id}) \oplus \textrm{Ker}(f-\textrm{Id})^{\perp}$, la matrice de $f$ est :
$$ \begin{pmatrix}
1 & 0 \\
0 & -1 \\
\end{pmatrix}$$
\end{enumerate}
\end{Theoreme}

\begin{Remarque}{} Rappelons qu'une symétrie orthogonale par rapport à un hyperplan est aussi appelée réflexion par rapport à cet hyperplan.
\end{Remarque}

\begin{Demonstration}{}
\vspace{14cm}
\end{Demonstration}

\newpage

$\phantom{tes}$

\vspace{15cm}



\begin{center}
\textbf{Plan d'étude d'une isométrie vectorielle en dimension 2}
\end{center}

\begin{enumerate}
\item Vérifier que l'endomorphisme est bien une isométrie vectorielle.
\item Calculer son déterminant pour savoir si c'est une rotation ou une réflexion.
\item Si c'est une rotation : trouver $\theta$ à l'aide des deux relations du théorème précédent.
\item Si c'est une réflexion : déterminer $\textrm{Ker}(f-\textrm{Id})$ puis de trouver son orthogonal.
\end{enumerate}

\medskip

\begin{Exemple}{} Soit $E= \mathbb{R}^2$ muni du produit scalaire usuel et orienté par la base canonique $\mathcal{B}$. Reconnaître l'endomorphisme $f$ de $E$ dont la matrice dans la base canonique est :
$$ M =\dfrac{1}{5} \begin{pmatrix}
4 & -3 \\
-3 & 4\\
\end{pmatrix}$$

\vspace{6cm}
\end{Exemple}

\begin{Proposition}{} Soit $E$ un espace euclidien orienté de dimension $2$. Alors les rotations de $E$ commutent entres-elles. Plus précisément : si $u$ est une rotation d'angle $\theta$ et $v$ est une rotation d'angle $\theta'$ alors $u \circ v \, (= v \circ u)$ est une rotation d'angle $\theta + \theta'$.
\end{Proposition}

\begin{Demonstration}{}
\vspace{3cm}
\end{Demonstration}

\subsection{Réduction des isométries vectorielles en dimension \texorpdfstring{$3$}{3}}
\begin{Theoreme}{Admis} Soient $E$ un espace euclidien orienté de dimension $3$ et $f \in \mathcal{SO}(E)$. Alors on est dans l'un et un seul des cas suivants :
\begin{enumerate}
\item $f= \textrm{Id}_E$.
\item L'ensemble $\textrm{Ker}(f - \textrm{Id}_E)$ est une droite vectorielle. En notant $D$ cette droite vectorielle (qui est un sous-espace propre de $f$ donc stable par $f$), son orthogonal $D^{\perp}$ est donc un plan stable par $f$. L'endomorphisme induit sur $D^{\perp}$ par $f$ est alors une rotation.

\medskip

Si $a$ est un vecteur unitaire dirigeant la droite $D$ alors en orientant $D^{\perp}$ par le choix du vecteur normal $a$, on peut on considérer une mesure $\theta$ de l'angle de cette rotation. La matrice de $f$ dans toute base orthonormée directe de $E$ de la forme $(e_1,e_2,a)$ est alors :
$$ \begin{pmatrix}
\cos(\theta) & -\sin(\theta) & 0 \\
\sin(\theta) & \cos(\theta) & 0 \\
0 & 0 & 1 \\
\end{pmatrix}$$
$D$ est alors l'ensemble des vecteurs invariants par $f$ : on dit que $f$ est une rotation d'axe $D$ et que $\theta$ est une mesure de l'angle de $f$ ($D^{\perp}$ étant orienté par $a$). Pour déterminer $\theta$ (modulo $2 \pi$), on peut utiliser que pour tout vecteur $x_0$ unitaire et orthogonal à $a$ :
$$ \textrm{Tr}(f) = 2 \cos(\theta)+1, \; \cos(\theta) = <x_0, f(x_0)>$$
et 
$$ x_0 \wedge f(x_0) = \sin(\theta) a , \; \sin(\theta) = [x_0, f(x_0),a]$$
Pour tout $x \in E$, on a :
$$ f(x) = \cos(\theta)(x-<a,x>a) + \sin(\theta) a \wedge x + <a,x>a$$
\end{enumerate}
\end{Theoreme}

\begin{Remarque}{} Pour vérifier qu'une matrice de $\mathcal{M}_3(\mathbb{R})$ appartient à $\mathcal{SO}_3(\mathbb{R})$, on procède de la sorte :
\begin{enumerate}
\item On vérifier que les colonnes de cette matrice sont deux à deux orthogonales et chacune de norme $1$.
\item On peut calculer le déterminant et montrer qu'il est égal à $1$ ou alors vérifier que $C_1 \wedge C_2 = C_3$ ce qui prouve que le déterminant de la matrice vaut $1$ ($C_1 \wedge C_2$ est soit égal à $C_3$ soit égal à $-C_3$).
\end{enumerate}
\end{Remarque}

\medskip

\begin{center}
\textbf{Représentation graphique d'une rotation en dimension 3}
\end{center}

\vspace{5cm}

%\begin{Demonstration}{}
%
%\vspace{13cm}
%\end{Demonstration}
%
%\newpage
%
%$\phantom{test}$

\vspace{4cm}
\begin{Remarque}{} Si on change $a$ en $-a$ (ce qui change l'orientation de $D$), cela revient à changer $\theta$ en $- \theta$.
\end{Remarque}

\begin{Theoreme}{Admis} Soient $E$ un espace euclidien orienté de dimension $3$ et $f \in \mathcal{O}(E)$ de déterminant égal à $-1$. Alors on est dans l'un et un seul des cas suivants :
\begin{enumerate}
\item $f= -\textrm{Id}_E$.
\item L'ensemble $\textrm{Ker}(f +\textrm{Id}_E)$ est une droite vectorielle. En notant $D$ cette droite vectorielle (qui est un sous-espace propre de $f$ donc stable par $f$), son orthogonal $D^{\perp}$ est donc un plan stable par $f$. L'endomorphisme induit sur $D^{\perp}$ par $f$ est alors une rotation.

\medskip

Si $a$ est un vecteur unitaire dirigeant la droite $D$ alors en orientant $D^{\perp}$ par le choix du vecteur normal $a$, on peut on considérer une mesure $\theta$ de l'angle de cette rotation. La matrice de $f$ dans toute base orthonormée directe de $E$ de la forme $(e_1,e_2,a)$ est alors :
$$ \begin{pmatrix}
\cos(\theta) & -\sin(\theta) & 0 \\
\sin(\theta) & \cos(\theta) & 0 \\
0 & 0 &- 1 \\
\end{pmatrix}$$
\end{enumerate}
\end{Theoreme}

\begin{Demonstration}{} Analogue à la précédente en remplaçant la valeur propre $1$ par la valeur propre $-1$.
\end{Demonstration}

\medskip

\begin{Exemple}{} Soit $E$ un espace euclidien orienté de dimension $3$. Déterminer la nature géométrique de l'endomorphisme $f$ dont la matrice $M$ dans une base orthonormée de $E$ est donnée par :
$$ M = \dfrac{1}{3} \begin{pmatrix}
2 & 1 & 2 \\
-2 & 2 & 1 \\
-1 & -2 & 2 \\
\end{pmatrix}$$
\end{Exemple}


\vspace{11.5cm}


\begin{ApplicationDirecte}{} Soit $\mathbb{R}^3$ muni du produit scalaire usuel. Déterminer la nature géométrique de l'endomorphisme $f$ dont la matrice $M$ dans la base canonique de $\mathbb{R}^3$ est donnée par :
$$ M =  \begin{pmatrix}
0 & 1 & 0 \\
0 & 0 & 1 \\
1 & 0 & 0 \\
\end{pmatrix}$$
\end{ApplicationDirecte}


\end{document}